{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sh20022002/probability_of_change/blob/main/trader_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "QXajTKy6m_Bl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pickle\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from torchrl.envs import EnvBase\n",
        "from tensordict import TensorDict\n",
        "from torchrl.envs.utils import step_mdp\n",
        "from torch.distributions import Categorical\n",
        "from tensordict import TensorDict\n",
        "from torchrl.collectors import SyncDataCollector\n",
        "from torchrl.data import ReplayBuffer, LazyTensorStorage\n",
        "from torchrl.objectives import A2CLoss, ValueEstimators\n",
        "from tensordict import TensorDictBase\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from torchrl.data import Unbounded, OneHot\n",
        "from torchrl.modules.distributions.continuous import TanhNormal\n",
        "from torchrl.modules import Actor\n",
        "from tensordict.nn import TensorDictModule\n",
        "from torchrl.modules import ProbabilisticActor\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import  Dataset\n",
        "import torch.optim as optim\n",
        "\n",
        "import collections\n",
        "import warnings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "MODEL_SAVE_PATH = \"trading_model.pth\"\n",
        "SP500_TICKERS = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
        "COLUMNS = ['Open', 'Close', 'Volume', 'MACD', 'ATR'] #change to open close volume macd rsi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_macd(df: pd.DataFrame, fast_period: int = 12, slow_period: int = 26, signal_period: int = 9) -> pd.DataFrame:\n",
        "    \"\"\"Calculate MACD, Signal Line, and MACD Histogram.\"\"\"\n",
        "    df = df.copy()\n",
        "    df['EMA_fast'] = df['Close'].ewm(span=fast_period, adjust=False).mean()\n",
        "    df['EMA_slow'] = df['Close'].ewm(span=slow_period, adjust=False).mean()\n",
        "    df['MACD'] = df['EMA_fast'] - df['EMA_slow']\n",
        "    return df['MACD']\n",
        "\n",
        "def calculate_atr(df: pd.DataFrame, period: int = 14) -> pd.Series:\n",
        "    \"\"\"Calculate Average True Range (ATR).\"\"\"\n",
        "    df = df.copy()\n",
        "    df['H-L'] = df['High'] - df['Low']\n",
        "    df['H-PC'] = np.abs(df['High'] - df['Close'].shift(1))\n",
        "    df['L-PC'] = np.abs(df['Low'] - df['Close'].shift(1))\n",
        "    df['TR'] = df[['H-L', 'H-PC', 'L-PC']].max(axis=1)\n",
        "    atr = df['TR'].ewm(span=period, adjust=False).mean()\n",
        "    return atr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class StockDataset(Dataset):\n",
        "    def __init__(self, tickers):\n",
        "        self.tickers = tickers\n",
        "        self.segmented_data = []\n",
        "        self.current_ticker_idx = 0\n",
        "\n",
        "        self._load_and_split_data()\n",
        "\n",
        "    def _load_and_split_data(self):\n",
        "        saved = False\n",
        "        for ticker in self.tickers:\n",
        "            print(f\"Processing ticker: {ticker}\")\n",
        "\n",
        "            try:\n",
        "                df = yf.download(ticker, period='max', progress=False)\n",
        "                if df.empty:\n",
        "                    print(f\"Warning: Empty data for ticker: {ticker}\")\n",
        "                    continue\n",
        "                \n",
        "                df = df.dropna()\n",
        "                \n",
        "                df['MACD'] = calculate_macd(df)\n",
        "                df['ATR'] = calculate_atr(df)\n",
        "\n",
        "                features = df[COLUMNS].dropna()\n",
        "                if features.empty:\n",
        "                    continue\n",
        "\n",
        "                    \n",
        "                # Select features to scale\n",
        "                scaler = StandardScaler()\n",
        "                scaled_data = scaler.fit_transform(features)\n",
        "\n",
        "                # Save the fitted scaler\n",
        "                if not saved:\n",
        "                    os.makedirs(\"data\", exist_ok=True)\n",
        "                    with open(\"data/scaler.pkl\", \"wb\") as f:\n",
        "                        pickle.dump(scaler, f)\n",
        "                        saved = True\n",
        "                        \n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error downloading data for {ticker}: {e}\")\n",
        "                continue        \n",
        "\n",
        "            scaled_values = scaled_data.astype(np.float32)\n",
        "            self.segmented_data.append((scaled_values, ticker))\n",
        "            self.current_ticker_idx += 1\n",
        "\n",
        "            \n",
        "    def __len__(self):\n",
        "        return len(self.segmented_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.segmented_data[idx]\n",
        "\n",
        "\n",
        "    def fetch_next_stock(self):\n",
        "        \"\"\"Returns a dataset segment in order, keeping track of stock index.\"\"\"\n",
        "        if not self.segmented_data:\n",
        "            return None, None  # No more stocks\n",
        "\n",
        "        if self.current_ticker_idx >= len(self.segmented_data):\n",
        "            self.current_ticker_idx = 0  # Loop back to start\n",
        "\n",
        "        segment, ticker = self.segmented_data[self.current_ticker_idx]\n",
        "        self.current_ticker_idx += 1\n",
        "        return segment, ticker\n",
        "\n",
        "    def save(self, path):\n",
        "        \"\"\"\n",
        "        Saves the StockDataset to a pickle file.\n",
        "\n",
        "        Args:\n",
        "            filepath (str): The path to the pickle file.\n",
        "        \"\"\"\n",
        "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "        with open(path, 'wb') as f:\n",
        "            pickle.dump(self, f)\n",
        "        print('Saved Dataset.')\n",
        "\n",
        "    @staticmethod\n",
        "    def load(path):\n",
        "        \"\"\"\n",
        "        Loads the StockDataset from a pickle file.\n",
        "\n",
        "        Args:\n",
        "            filepath (str): The path to the pickle file.\n",
        "\n",
        "        Returns:\n",
        "            StockDataset: The loaded StockDataset object.\n",
        "        \"\"\"\n",
        "        with open(path, 'rb') as f:\n",
        "            return pickle.load(f)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TradingEnv(EnvBase):\n",
        "    def __init__(self, df: pd.DataFrame, window_size=30):\n",
        "        super().__init__()\n",
        "\n",
        "        if isinstance(df, np.ndarray):\n",
        "            df = pd.DataFrame(df)\n",
        "\n",
        "        if len(df) < window_size:\n",
        "            raise ValueError(f\"Insufficient data: need at least {window_size} rows, got {len(df)}.\")\n",
        "\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.initial_balance = 1000.0\n",
        "        self.balance = 1000.0\n",
        "        self.net_worth = 1000.0\n",
        "        self.window_size = window_size\n",
        "        self.current_step = 0\n",
        "\n",
        "        obs_dim = window_size * self.df.shape[1]\n",
        "        self.observation_spec = Unbounded(shape=(obs_dim,))\n",
        "        self.action_spec = OneHot(n=4)\n",
        "        self._set_seed(0)\n",
        "\n",
        "    def _reset(self, tensordict=None):\n",
        "        self.current_step = self.window_size\n",
        "        self.balance = self.initial_balance\n",
        "        self.net_worth = self.initial_balance\n",
        "        self.positions = []\n",
        "        self.position_type = None\n",
        "        self.trades = []\n",
        "\n",
        "        obs = self._get_observation()\n",
        "        return TensorDict({\"observation\": obs.unsqueeze(0)}, batch_size=[])\n",
        "\n",
        "    def _get_observation(self):\n",
        "        frame = self.df.iloc[self.current_step - self.window_size:self.current_step].copy()\n",
        "        frame[\"Balance\"] = self.balance\n",
        "        frame[\"NetWorth\"] = self.net_worth\n",
        "\n",
        "        obs = torch.tensor(frame.astype(np.float32).values, dtype=torch.float32)\n",
        "        return obs\n",
        "\n",
        "    def _set_seed(self, seed: int):\n",
        "        torch.manual_seed(seed)\n",
        "        np.random.seed(seed)\n",
        "        random.seed(seed)\n",
        "        return seed\n",
        "\n",
        "    def _step(self, tensordict):\n",
        "        action = tensordict[\"action\"]\n",
        "\n",
        "        if action.ndim == 0:\n",
        "            action = action.unsqueeze(0)\n",
        "\n",
        "        batch_size = action.shape[0]\n",
        "        rewards = torch.zeros(batch_size)\n",
        "        dones = torch.zeros(batch_size, dtype=torch.bool)\n",
        "        next_observations = []\n",
        "\n",
        "        commission_rate = 0.001  # 0.1%\n",
        "        tax_rate = 0.15          # 15% profit tax\n",
        "        leverage = 1.0           # 2x leverage\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            a = action[i].item()\n",
        "            current_price = self.stock_data[self.current_step]\n",
        "            next_price = self.stock_data[self.current_step + 1] if self.current_step + 1 < len(self.stock_data) else current_price\n",
        "            price_diff = next_price - current_price\n",
        "\n",
        "            reward = 0.0\n",
        "\n",
        "            if a == 1:  # Buy\n",
        "                profit = price_diff * leverage\n",
        "                tax = tax_rate * max(profit, 0.0)\n",
        "                cost = commission_rate * current_price * leverage\n",
        "                reward = profit - tax - cost\n",
        "            elif a == 2:  # Sell\n",
        "                profit = -price_diff * leverage\n",
        "                tax = tax_rate * max(profit, 0.0)\n",
        "                cost = commission_rate * current_price * leverage\n",
        "                reward = profit - tax - cost\n",
        "            elif a == 3:  # Short\n",
        "                profit = -price_diff * leverage\n",
        "                tax = tax_rate * max(profit, 0.0)\n",
        "                cost = commission_rate * current_price * leverage\n",
        "                reward = profit - tax - cost\n",
        "            # a == 0 (Hold): reward stays 0\n",
        "\n",
        "            rewards[i] = reward\n",
        "            dones[i] = self.current_step + 1 >= len(self.stock_data) - 1\n",
        "\n",
        "            next_obs = self._get_next_observation()\n",
        "            next_observations.append(next_obs)\n",
        "\n",
        "        self.current_step += 1\n",
        "        next_observations = torch.stack(next_observations, dim=0)\n",
        "\n",
        "        return TensorDict({\n",
        "            \"reward\": rewards,\n",
        "            \"done\": dones,\n",
        "            \"observation\": next_observations,\n",
        "        }, batch_size=[batch_size])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model(stock_data, model):\n",
        "    \"\"\"Evaluates the model on stock data and returns total reward.\"\"\"\n",
        "    env = TradingEnv(stock_data)\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "    actions = []\n",
        "\n",
        "    while not done:\n",
        "        with torch.inference_mode:\n",
        "            state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0)\n",
        "            logits, value, _ = model(state_tensor)\n",
        "            action = torch.argmax(logits).item()\n",
        "\n",
        "\n",
        "        actions.append(action)\n",
        "        state, reward, done, _ = env.step(action)\n",
        "        total_reward += reward\n",
        "\n",
        "    return total_reward, actions\n",
        "\n",
        "# Function to plot evaluation results\n",
        "def plot_evaluation_results(stock_data, actions):\n",
        "    \"\"\"Plots stock data and overlays model evaluation results.\"\"\"\n",
        "    close_prices = stock_data[:, 3]  # Close prices\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(close_prices, label=\"Close Price\", color='black')\n",
        "\n",
        "    buy_signals = [i for i in range(len(actions)) if actions[i] == 1]\n",
        "    sell_signals = [i for i in range(len(actions)) if actions[i] == 2]\n",
        "\n",
        "    plt.scatter(buy_signals, close_prices[buy_signals], color='green', marker='^', label='Buy')\n",
        "    plt.scatter(sell_signals, close_prices[sell_signals], color='red', marker='v', label='Sell')\n",
        "\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel(\"Stock Price\")\n",
        "    plt.legend()\n",
        "    plt.title(f\"Model Evaluation Results\")\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "id": "UsVD4Tjim_Bp"
      },
      "outputs": [],
      "source": [
        "\n",
        "if os.path.exists(\"data/stock_dataset.pkl\"):\n",
        "    dataset = StockDataset.load(\"data/stock_dataset.pkl\")\n",
        "else:\n",
        "    tickers = pd.read_html(SP500_TICKERS)[0]['Symbol'].tolist()\n",
        "    dataset = StockDataset(tickers)\n",
        "    dataset.save(\"data/stock_dataset.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(array([[-0.7405194 , -0.7300623 , -0.87796915, -0.07685785, -0.66487986],\n",
            "       [-0.7405194 , -0.72995913, -0.7758922 , -0.07643412, -0.66538656],\n",
            "       [-0.7405194 , -0.72995913, -0.87796915, -0.07610697, -0.6665013 ],\n",
            "       ...,\n",
            "       [ 2.6384516 ,  2.5597277 ,  0.9142302 , -4.8513846 ,  7.275909  ],\n",
            "       [ 2.5477831 ,  2.628197  ,  0.20786287, -4.0690956 ,  6.952138  ],\n",
            "       [ 2.6292393 ,  2.5903203 , -0.10967056, -3.566246  ,  6.235909  ]],\n",
            "      dtype=float32), 'MMM')\n"
          ]
        }
      ],
      "source": [
        "print(dataset.fetch_next_stock())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class StockLSTM(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=128, lstm_layers=2, fc_dim=64, output_dim=4):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.lstm_layers = lstm_layers\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, lstm_layers, batch_first=True, dropout=0.2 if lstm_layers > 1 else 0.0)\n",
        "        self.norm = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "        self.actor = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, fc_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(fc_dim, output_dim)\n",
        "        )\n",
        "\n",
        "        self.critic = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, fc_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(fc_dim, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, tensordict: TensorDictBase) -> TensorDictBase:\n",
        "        obs = tensordict[\"observation\"]\n",
        "        # Get the batch size and sequence length safely\n",
        "        batch_size, seq_len = obs.size(0), obs.size(1)\n",
        "        \n",
        "        # If obs has more than 3 dimensions (batch, seq, features), flatten it\n",
        "        if obs.ndim > 3:\n",
        "            obs = obs.view(batch_size, seq_len, -1)\n",
        "        \n",
        "        output, _ = self.lstm(obs)\n",
        "        output = self.norm(output)\n",
        "        tensordict[\"_features\"] = output\n",
        "        return tensordict\n",
        "\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {},
      "outputs": [],
      "source": [
        "def init_or_load(input_dim: int = 7,\n",
        "                     output_dim: int = 3,\n",
        "                     lr: float = 1e-3,\n",
        "                     memory_size: int = 10_000):\n",
        "    \"\"\"\n",
        "    Returns (model, optimizer, memory), loading pretrained weights if available.\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Using device:\", device)\n",
        "\n",
        "    model = StockLSTM(input_dim=input_dim, output_dim=output_dim).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    memory = collections.deque(maxlen=memory_size)\n",
        "\n",
        "    if os.path.exists(MODEL_SAVE_PATH):\n",
        "        model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
        "        print(f\" Loaded existing model from {MODEL_SAVE_PATH}\")\n",
        "    else:\n",
        "        print(\"  No existing model found — initialized new network.\")\n",
        "\n",
        "    return model, optimizer, memory, device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def convert_state(state):\n",
        "    if isinstance(state, np.ndarray):\n",
        "        state = torch.tensor(state, dtype=torch.float32)\n",
        "    if isinstance(state, list):\n",
        "        state = torch.tensor(state, dtype=torch.float32)\n",
        "    if state.ndim == 2:\n",
        "        state = state.unsqueeze(0)\n",
        "    return state\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def train(dataset, episodes=30, gamma=0.95, lr=1e-3):\n",
        "    model, optimizer, _, device = init_or_load(input_dim=7, output_dim=4, lr=lr)\n",
        "    model = model.to(device)\n",
        "    \n",
        "\n",
        "    if os.path.exists(MODEL_SAVE_PATH):\n",
        "        model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
        "        print(\"Loaded existing model.\")\n",
        "\n",
        "    window_size = 7\n",
        "\n",
        "    while True:\n",
        "        stock_data, ticker = dataset.fetch_next_stock()\n",
        "        if stock_data is None:\n",
        "            print(\"All data segments processed, restarting training loop...\")\n",
        "            break\n",
        "\n",
        "        if isinstance(stock_data, np.ndarray):\n",
        "            stock_data = pd.DataFrame(stock_data)\n",
        "\n",
        "        if len(stock_data) < window_size:\n",
        "            print(f\"Skipping stock {ticker}: only {len(stock_data)} rows (<{window_size}).\")\n",
        "            continue\n",
        "\n",
        "        env = TradingEnv(stock_data, window_size=window_size)\n",
        "\n",
        "        collector = SyncDataCollector(\n",
        "            create_env_fn=lambda: env,\n",
        "            policy=lambda td: TensorDict({\"action\": Categorical(logits=model(td)[\"_features\"]).sample()}, batch_size=[]),\n",
        "            frames_per_batch=episodes,\n",
        "            total_frames=episodes\n",
        "        ) \n",
        "\n",
        "        feature_extractor = TensorDictModule(\n",
        "            module=model,\n",
        "            in_keys=[\"observation\"],\n",
        "            out_keys=[\"_features\"]\n",
        "        )\n",
        "\n",
        "        actor_net = TensorDictModule(\n",
        "            module=model.actor,        # model.actor outputs logits\n",
        "            in_keys=[\"_features\"],\n",
        "            out_keys=[\"logits\"]\n",
        "        )\n",
        "\n",
        "        actor = ProbabilisticActor(\n",
        "            module=actor_net,\n",
        "            in_keys=[\"_features\"],\n",
        "            out_keys=[\"action\"],\n",
        "            spec=None  # optional if you have action spec\n",
        "        )\n",
        "\n",
        "        # Critic\n",
        "        critic = TensorDictModule(\n",
        "            module=model.critic,\n",
        "            in_keys=[\"_features\"],\n",
        "            out_keys=[\"state_value\"]\n",
        "        )\n",
        "\n",
        "\n",
        "        loss_module = A2CLoss(actor_network=actor, critic_network=critic)\n",
        "        loss_module.make_value_estimator(ValueEstimators.TD0, gamma=gamma)\n",
        "        buffer = ReplayBuffer(storage=LazyTensorStorage(max_size=episodes))\n",
        "\n",
        "        for i, tensordict_data in enumerate(collector):\n",
        "\n",
        "            tensordict_data = feature_extractor(tensordict_data)\n",
        "\n",
        "            buffer.extend(tensordict_data)\n",
        "\n",
        "            sampled_data = buffer.sample(batch_size=episodes)\n",
        "\n",
        "            loss_td = loss_module(sampled_data)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss_td[\"loss\"].backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            print(f\"[{ticker}] Episode {i+1}/{episodes} | Loss: {loss_td['loss'].item():.4f}\")\n",
        "\n",
        "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "        print(f\"[{ticker}] Training complete and model saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VPPJh-7am_Bq",
        "outputId": "df191946-a1db-4c90-d1c9-5fa4f799087c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "  No existing model found — initialized new network.\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "a Tensor with 7 elements cannot be converted to Scalar",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[182], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run training\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[181], line 65\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(dataset, episodes, gamma, lr)\u001b[0m\n\u001b[0;32m     62\u001b[0m loss_module\u001b[38;5;241m.\u001b[39mmake_value_estimator(ValueEstimators\u001b[38;5;241m.\u001b[39mTD0, gamma\u001b[38;5;241m=\u001b[39mgamma)\n\u001b[0;32m     63\u001b[0m buffer \u001b[38;5;241m=\u001b[39m ReplayBuffer(storage\u001b[38;5;241m=\u001b[39mLazyTensorStorage(max_size\u001b[38;5;241m=\u001b[39mepisodes))\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, tensordict_data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(collector):\n\u001b[0;32m     67\u001b[0m     tensordict_data \u001b[38;5;241m=\u001b[39m feature_extractor(tensordict_data)\n\u001b[0;32m     69\u001b[0m     buffer\u001b[38;5;241m.\u001b[39mextend(tensordict_data)\n",
            "File \u001b[1;32mc:\\Users\\shmue\\projects\\python\\open_pojects\\probability_of_market_movment\\.venv\\lib\\site-packages\\torchrl\\collectors\\collectors.py:264\u001b[0m, in \u001b[0;36mDataCollectorBase.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[TensorDictBase]:\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 264\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator()\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    266\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshutdown()\n",
            "File \u001b[1;32mc:\\Users\\shmue\\projects\\python\\open_pojects\\probability_of_market_movment\\.venv\\lib\\site-packages\\torchrl\\collectors\\collectors.py:1081\u001b[0m, in \u001b[0;36mSyncDataCollector.iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1079\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_frames \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_frames:\n\u001b[0;32m   1080\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1081\u001b[0m     tensordict_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1082\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tensordict_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1083\u001b[0m         \u001b[38;5;66;03m# if a replay buffer is passed, there is no tensordict_out\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m         \u001b[38;5;66;03m#  frames are updated within the rollout function\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\shmue\\projects\\python\\open_pojects\\probability_of_market_movment\\.venv\\lib\\site-packages\\torchrl\\_utils.py:546\u001b[0m, in \u001b[0;36maccept_remote_rref_invocation.<locals>.unpack_rref_and_invoke_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _os_is_windows \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_distributed_rpc\u001b[38;5;241m.\u001b[39mPyRRef):\n\u001b[0;32m    545\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocal_value()\n\u001b[1;32m--> 546\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\shmue\\projects\\python\\open_pojects\\probability_of_market_movment\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\shmue\\projects\\python\\open_pojects\\probability_of_market_movment\\.venv\\lib\\site-packages\\torchrl\\collectors\\collectors.py:1244\u001b[0m, in \u001b[0;36mSyncDataCollector.rollout\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1243\u001b[0m     env_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shuttle\n\u001b[1;32m-> 1244\u001b[0m env_output, env_next_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_and_maybe_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shuttle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m env_output:\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;66;03m# ad-hoc update shuttle\u001b[39;00m\n\u001b[0;32m   1248\u001b[0m     next_data \u001b[38;5;241m=\u001b[39m env_output\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\shmue\\projects\\python\\open_pojects\\probability_of_market_movment\\.venv\\lib\\site-packages\\torchrl\\envs\\common.py:3440\u001b[0m, in \u001b[0;36mEnvBase.step_and_maybe_reset\u001b[1;34m(self, tensordict)\u001b[0m\n\u001b[0;32m   3438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tensordict\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice:\n\u001b[0;32m   3439\u001b[0m     tensordict \u001b[38;5;241m=\u001b[39m tensordict\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m-> 3440\u001b[0m tensordict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3441\u001b[0m \u001b[38;5;66;03m# done and truncated are in done_keys\u001b[39;00m\n\u001b[0;32m   3442\u001b[0m \u001b[38;5;66;03m# We read if any key is done.\u001b[39;00m\n\u001b[0;32m   3443\u001b[0m tensordict_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step_mdp(tensordict)\n",
            "File \u001b[1;32mc:\\Users\\shmue\\projects\\python\\open_pojects\\probability_of_market_movment\\.venv\\lib\\site-packages\\torchrl\\envs\\common.py:1985\u001b[0m, in \u001b[0;36mEnvBase.step\u001b[1;34m(self, tensordict)\u001b[0m\n\u001b[0;32m   1981\u001b[0m     tensordict_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size\n\u001b[0;32m   1983\u001b[0m next_preset \u001b[38;5;241m=\u001b[39m tensordict\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1985\u001b[0m next_tensordict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1986\u001b[0m next_tensordict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step_proc_data(next_tensordict)\n\u001b[0;32m   1987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m next_preset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1988\u001b[0m     \u001b[38;5;66;03m# tensordict could already have a \"next\" key\u001b[39;00m\n\u001b[0;32m   1989\u001b[0m     \u001b[38;5;66;03m# this could be done more efficiently by not excluding but just passing\u001b[39;00m\n\u001b[0;32m   1990\u001b[0m     \u001b[38;5;66;03m# the necessary keys\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[174], line 64\u001b[0m, in \u001b[0;36mTradingEnv._step\u001b[1;34m(self, tensordict)\u001b[0m\n\u001b[0;32m     61\u001b[0m leverage \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m           \u001b[38;5;66;03m# 2x leverage\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size):\n\u001b[1;32m---> 64\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m     current_price \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstock_data[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_step]\n\u001b[0;32m     66\u001b[0m     next_price \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstock_data[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstock_data) \u001b[38;5;28;01melse\u001b[39;00m current_price\n",
            "\u001b[1;31mRuntimeError\u001b[0m: a Tensor with 7 elements cannot be converted to Scalar"
          ]
        }
      ],
      "source": [
        "\n",
        "# Run training\n",
        "train(dataset, episodes=10)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
