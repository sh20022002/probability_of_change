{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sh20022002/probability_of_change/blob/main/trader_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXajTKy6m_Bl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pickle\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import gym\n",
        "from gym import spaces\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Categorical\n",
        "\n",
        "import random\n",
        "import collections\n",
        "import warnings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "MODEL_SAVE_PATH = \"trading_model.pth\"\n",
        "SP500_TICKERS = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
        "\n",
        "\n",
        "class StockDataset:\n",
        "    def __init__(self, tickers, num_segments=10):\n",
        "        self.tickers = tickers\n",
        "        self.num_segments = num_segments  # Number of parts to divide the dataset into\n",
        "        self.segmented_data = []  # Preprocessed data\n",
        "        self.current_ticker_idx = 0  # Keep track of which stock is being processed\n",
        "\n",
        "        self._load_and_split_data()\n",
        "\n",
        "    def _load_and_split_data(self):\n",
        "        \"\"\"Loads full dataset once and splits into shuffled segments\"\"\"\n",
        "        scaler_saved = False\n",
        "        scaler = None\n",
        "\n",
        "        for ticker in self.tickers:\n",
        "            try:\n",
        "                stock_data = yf.download(ticker, period='max', progress=False)\n",
        "                if stock_data.empty:\n",
        "                    print(f\"Warning: Empty data for ticker: {ticker}\")\n",
        "                    continue\n",
        "\n",
        "                df = stock_data[['Open', 'High', 'Low', 'Close', 'Volume']].dropna()\n",
        "                df['Return'] = df['Close'].pct_change()\n",
        "                df['SMA150'] = df['Close'].rolling(window=150).mean()\n",
        "                df.dropna(inplace=True)\n",
        "\n",
        "                features_df = df[['Open', 'Close', 'Return', 'Volume', 'SMA150']]\n",
        "                if features_df.empty:\n",
        "                    continue\n",
        "\n",
        "                print(f\"Processing ticker: {ticker}\")\n",
        "\n",
        "                variances = features_df.var()\n",
        "                features_df = features_df[[col for col in features_df.columns if variances[col] != 0]]\n",
        "\n",
        "                if scaler is None:\n",
        "                    scaler = StandardScaler().fit(features_df)\n",
        "\n",
        "                columns = features_df.columns\n",
        "                index = features_df.index\n",
        "\n",
        "                features_df = pd.DataFrame(\n",
        "                    scaler.transform(features_df),\n",
        "                    columns=columns,\n",
        "                    index=index\n",
        "                )\n",
        "\n",
        "                scaled_values = features_df.astype(np.float32).values\n",
        "                segment_size = len(scaled_values) // self.num_segments\n",
        "                segments = [scaled_values[i * segment_size:(i + 1) * segment_size] for i in range(self.num_segments)]\n",
        "                self.segmented_data.extend([(segment, ticker) for segment in segments])\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error downloading data for {ticker}: {e}\")\n",
        "                continue\n",
        "\n",
        "        if scaler is not None and not scaler_saved:\n",
        "            os.makedirs(\"data\", exist_ok=True)\n",
        "            with open(\"data/scaler.pkl\", \"wb\") as f:\n",
        "                pickle.dump(scaler, f)\n",
        "            print(\"Scaler saved\")\n",
        "\n",
        "    def fetch_next_stock(self):\n",
        "        \"\"\"Returns a dataset segment in order, keeping track of stock index.\"\"\"\n",
        "        if not self.segmented_data:\n",
        "            return None, None  # No more stocks\n",
        "\n",
        "        if self.current_ticker_idx >= len(self.segmented_data):\n",
        "            self.current_ticker_idx = 0  # Loop back to start\n",
        "\n",
        "        segment, ticker = self.segmented_data[self.current_ticker_idx]\n",
        "        self.current_ticker_idx += 1\n",
        "        return segment, ticker\n",
        "\n",
        "    def save(self, path):\n",
        "        \"\"\"\n",
        "        Saves the StockDataset to a pickle file.\n",
        "\n",
        "        Args:\n",
        "            filepath (str): The path to the pickle file.\n",
        "        \"\"\"\n",
        "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "        with open(path, 'wb') as f:\n",
        "            pickle.dump(self, f)\n",
        "        print('Saved Dataset.')\n",
        "\n",
        "    @staticmethod\n",
        "    def load(path):\n",
        "        \"\"\"\n",
        "        Loads the StockDataset from a pickle file.\n",
        "\n",
        "        Args:\n",
        "            filepath (str): The path to the pickle file.\n",
        "\n",
        "        Returns:\n",
        "            StockDataset: The loaded StockDataset object.\n",
        "        \"\"\"\n",
        "        with open(path, 'rb') as f:\n",
        "            return pickle.load(f)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Cell 2: Preprocess Data\n",
        "def preprocess_data(df):\n",
        "    \"\"\"Preprocesses stock data by adding features and scaling.\"\"\"\n",
        "    df['Return'] = df['Close'].pct_change()\n",
        "    df['SMA150'] = df['Close'].rolling(window=150).mean()\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    # Select features to scale\n",
        "    features = df[['Open', 'Close', 'Return', 'Volume', 'SMA150']]\n",
        "    scaler = StandardScaler()\n",
        "    scaled_data = scaler.fit_transform(features)\n",
        "\n",
        "    # Save the fitted scaler\n",
        "\n",
        "    os.makedirs(\"data\", exist_ok=True)\n",
        "    with open(\"data/scaler.pkl\", \"wb\") as f:\n",
        "        pickle.dump(scaler, f)\n",
        "\n",
        "    return scaled_data, scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TradingEnv(gym.Env):\n",
        "    def __init__(self, df, initial_balance=10000, scaler=None, window_size=30):\n",
        "        super(TradingEnv, self).__init__()\n",
        "\n",
        "        if isinstance(df, np.ndarray):\n",
        "            df = pd.DataFrame(df)\n",
        "\n",
        "        if len(df) < window_size:\n",
        "            raise ValueError(f\"Insufficient data: need at least {window_size} rows, got {len(df)}.\")\n",
        "\n",
        "        self.df = df.reset_index(drop=True) #?\n",
        "        self.initial_balance = initial_balance\n",
        "        self.scaler = scaler\n",
        "        self.window_size = window_size\n",
        "        self.action_space = spaces.Discrete(4)\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=-np.inf, high=np.inf, \n",
        "            shape=(window_size, df.shape[1] + 2), \n",
        "            dtype=np.float32\n",
        "        )\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_step = self.window_size\n",
        "        self.balance = self.initial_balance\n",
        "        self.net_worth = self.initial_balance\n",
        "        self.positions = []\n",
        "        self.position_type = None\n",
        "        self.trades = []\n",
        "        return self._get_observation()\n",
        "\n",
        "    def _get_observation(self):\n",
        "        frame = self.df.iloc[self.current_step - self.window_size:self.current_step]\n",
        "        obs = frame.copy()\n",
        "        obs['Balance'] = self.balance\n",
        "        obs['NetWorth'] = self.net_worth\n",
        "\n",
        "        try:\n",
        "            if self.scaler is not None:\n",
        "                obs = self.scaler.transform(obs)\n",
        "        except Exception as e:\n",
        "            warnings.warn(f\"Scaler transform failed: {e}. Proceeding without scaling.\")\n",
        "\n",
        "        return obs.astype(np.float32)\n",
        "\n",
        "    def step(self, action):\n",
        "        done = False\n",
        "        reward = 0\n",
        "        current_price = self.df.loc[self.current_step, 'Close'] #?\n",
        "\n",
        "        if action == 0:  # Buy\n",
        "            if self.position_type is None:\n",
        "                self.positions.append(current_price)\n",
        "                self.position_type = 'long'\n",
        "            elif self.position_type == 'short':\n",
        "                entry = self.positions.pop(0)\n",
        "                profit = entry - current_price\n",
        "                reward += profit\n",
        "                self.balance += profit\n",
        "                if not self.positions:\n",
        "                    self.position_type = None\n",
        "\n",
        "        elif action == 1:  # Sell\n",
        "            if self.position_type == 'long':\n",
        "                entry = self.positions.pop(0)\n",
        "                profit = current_price - entry\n",
        "                reward += profit\n",
        "                self.balance += profit\n",
        "                if not self.positions:\n",
        "                    self.position_type = None\n",
        "\n",
        "        elif action == 2:  # Short\n",
        "            if self.position_type is None:\n",
        "                self.positions.append(current_price)\n",
        "                self.position_type = 'short'\n",
        "            elif self.position_type == 'long':\n",
        "                entry = self.positions.pop(0)\n",
        "                profit = current_price - entry\n",
        "                reward += profit\n",
        "                self.balance += profit\n",
        "                if not self.positions:\n",
        "                    self.position_type = None\n",
        "\n",
        "        elif action == 3:  # Cover\n",
        "            if self.position_type == 'short':\n",
        "                entry = self.positions.pop(0)\n",
        "                profit = entry - current_price\n",
        "                reward += profit\n",
        "                self.balance += profit\n",
        "                if not self.positions:\n",
        "                    self.position_type = None\n",
        "\n",
        "        self.net_worth = self.balance\n",
        "        self.trades.append((self.current_step, action, current_price, reward))\n",
        "\n",
        "        self.current_step += 1\n",
        "        if self.current_step >= len(self.df):\n",
        "            done = True\n",
        "\n",
        "        return self._get_observation(), reward, done, {}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model(stock_data, model):\n",
        "    \"\"\"Evaluates the model on stock data and returns total reward.\"\"\"\n",
        "    env = TradingEnv(stock_data)\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "    actions = []\n",
        "\n",
        "    while not done:\n",
        "        with torch.no_grad():\n",
        "            state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0)\n",
        "            logits, value, _ = model(state_tensor)\n",
        "            action = torch.argmax(logits).item()\n",
        "\n",
        "\n",
        "        actions.append(action)\n",
        "        state, reward, done, _ = env.step(action)\n",
        "        total_reward += reward\n",
        "\n",
        "    return total_reward, actions\n",
        "\n",
        "# Function to plot evaluation results\n",
        "def plot_evaluation_results(stock_data, actions):\n",
        "    \"\"\"Plots stock data and overlays model evaluation results.\"\"\"\n",
        "    close_prices = stock_data[:, 3]  # Close prices\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(close_prices, label=\"Close Price\", color='black')\n",
        "\n",
        "    buy_signals = [i for i in range(len(actions)) if actions[i] == 1]\n",
        "    sell_signals = [i for i in range(len(actions)) if actions[i] == 2]\n",
        "\n",
        "    plt.scatter(buy_signals, close_prices[buy_signals], color='green', marker='^', label='Buy')\n",
        "    plt.scatter(sell_signals, close_prices[sell_signals], color='red', marker='v', label='Sell')\n",
        "\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel(\"Stock Price\")\n",
        "    plt.legend()\n",
        "    plt.title(f\"Model Evaluation Results\")\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "def init_or_load(input_dim: int = 7,\n",
        "                     output_dim: int = 3,\n",
        "                     lr: float = 1e-3,\n",
        "                     memory_size: int = 10_000):\n",
        "    \"\"\"\n",
        "    Returns (model, optimizer, memory), loading pretrained weights if available.\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Using device:\", device)\n",
        "\n",
        "    model = StockLSTM(input_dim=input_dim, output_dim=output_dim).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    memory = collections.deque(maxlen=memory_size)\n",
        "\n",
        "    if os.path.exists(MODEL_SAVE_PATH):\n",
        "        model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
        "        print(f\" Loaded existing model from {MODEL_SAVE_PATH}\")\n",
        "    else:\n",
        "        print(\"  No existing model found — initialized new network.\")\n",
        "\n",
        "    return model, optimizer, memory, device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "UsVD4Tjim_Bp"
      },
      "outputs": [],
      "source": [
        "\n",
        "if os.path.exists(\"data/stock_dataset.pkl\"):\n",
        "    dataset = StockDataset.load(\"data/stock_dataset.pkl\")\n",
        "else:\n",
        "    tickers = pd.read_html(SP500_TICKERS)[0]['Symbol'].tolist()\n",
        "    dataset = StockDataset(tickers, num_segments=10)\n",
        "    dataset.save(\"data/stock_dataset.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "class StockLSTM(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=128, lstm_layers=2, fc_dim=64, output_dim=3):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.lstm_layers = lstm_layers\n",
        "\n",
        "        dropout = 0.2 if lstm_layers > 1 else 0.0\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=lstm_layers, batch_first=True, dropout=dropout)\n",
        "\n",
        "        self.layer_norm = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "        # Actor head\n",
        "        self.actor_fc1 = nn.Linear(hidden_dim, fc_dim)\n",
        "        self.actor_fc2 = nn.Linear(fc_dim, output_dim)  # logits for actions\n",
        "\n",
        "        # Critic head\n",
        "        self.critic_fc1 = nn.Linear(hidden_dim, fc_dim)\n",
        "        self.critic_fc2 = nn.Linear(fc_dim, 1)  # state-value\n",
        "\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, x, hidden_state=None):\n",
        "        # x: (batch_size, seq_len, input_dim)\n",
        "        if hidden_state is None:\n",
        "            h0 = torch.zeros(self.lstm_layers, x.size(0), self.hidden_dim).to(x.device)\n",
        "            c0 = torch.zeros(self.lstm_layers, x.size(0), self.hidden_dim).to(x.device)\n",
        "            hidden_state = (h0, c0)\n",
        "\n",
        "        lstm_out, new_hidden = self.lstm(x, hidden_state)\n",
        "        last_output = lstm_out[:, -1, :]  # use last output\n",
        "        normed = self.layer_norm(last_output)\n",
        "        dropped = self.dropout(normed)\n",
        "\n",
        "        # Actor\n",
        "        actor_hidden = F.relu(self.actor_fc1(dropped))\n",
        "        policy_logits = self.actor_fc2(actor_hidden)\n",
        "\n",
        "        # Critic\n",
        "        critic_hidden = F.relu(self.critic_fc1(dropped))\n",
        "        value = self.critic_fc2(critic_hidden)\n",
        "\n",
        "        return policy_logits, value, new_hidden\n",
        "\n",
        "\n",
        "# Assuming these functions/constants are defined elsewhere:\n",
        "# init_or_load, MODEL_SAVE_PATH, TradingEnv, evaluate_model, plot_evaluation_results\n",
        "\n",
        "def convert_state(state, device):\n",
        "    \"\"\"\n",
        "    Ensure 'state' is a sequence with shape (window_size, feature_dim) \n",
        "    and convert to a torch tensor with added batch dimension.\n",
        "    \"\"\"\n",
        "    # If state is not a list or np.ndarray, wrap it in a list.\n",
        "    if not isinstance(state, (list, np.ndarray)):\n",
        "        state = [state]\n",
        "    # Convert to a NumPy array (if it isn't already)\n",
        "    state = np.array(state)\n",
        "    state_tensor = torch.tensor(state, dtype=torch.float32, device=device)\n",
        "    # Check dimensions:\n",
        "    #   If state_tensor is 1D, assume it's a single observation vector => unsqueeze twice: (1,1,feature_dim)\n",
        "    #   If state_tensor is 2D, assume it's (window_size, feature_dim) => unsqueeze batch dim: (1, window_size, feature_dim)\n",
        "    if state_tensor.ndim == 1:\n",
        "        state_tensor = state_tensor.unsqueeze(0).unsqueeze(0)\n",
        "    elif state_tensor.ndim == 2:\n",
        "        state_tensor = state_tensor.unsqueeze(0)\n",
        "    # If it's already 3D, assume batch dimension is present\n",
        "    return state_tensor\n",
        "\n",
        "def train_on_sp500(dataset, episodes=10, batch_size=64, gamma=0.95, lr=0.001, save_interval=30):\n",
        "    model, optimizer, _, device = init_or_load(input_dim=7, output_dim=3, lr=lr)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    if os.path.exists(MODEL_SAVE_PATH):\n",
        "        model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
        "        print(\"Loaded existing model.\")\n",
        "\n",
        "    window_size = 7\n",
        "\n",
        "    while True:\n",
        "        stock_data, ticker = dataset.fetch_next_stock()\n",
        "        if stock_data is None:\n",
        "            print(\"All data segments processed, restarting training loop...\")\n",
        "            break\n",
        "\n",
        "        if isinstance(stock_data, np.ndarray):\n",
        "            stock_data = pd.DataFrame(stock_data)\n",
        "\n",
        "        if len(stock_data) < window_size:\n",
        "            print(f\"Skipping stock {ticker}: only {len(stock_data)} rows (<{window_size}).\")\n",
        "            continue\n",
        "\n",
        "        env = TradingEnv(stock_data, window_size=window_size)\n",
        "\n",
        "        wins = 0\n",
        "        action_counter = collections.Counter()\n",
        "\n",
        "        for episode in range(episodes):\n",
        "            state = env.reset()\n",
        "            action_counter.clear()\n",
        "            done = False\n",
        "            total_reward = 0\n",
        "            PROFIT = 0\n",
        "            tax_credit = 0\n",
        "\n",
        "            episode_states = []\n",
        "            episode_actions = []\n",
        "            episode_rewards = []\n",
        "\n",
        "            while not done:\n",
        "                # Ensure state is in the correct sequence format\n",
        "                state_tensor = convert_state(state, device)\n",
        "                logits, value, _ = model(state_tensor)\n",
        "                dist = Categorical(logits=logits)\n",
        "                action = dist.sample().item()\n",
        "\n",
        "                next_state, reward, done, _ = env.step(action)\n",
        "\n",
        "                episode_states.append(state)\n",
        "                episode_actions.append(action)\n",
        "                episode_rewards.append(reward)\n",
        "\n",
        "                state = next_state\n",
        "                action_counter[action] += 1\n",
        "\n",
        "            # Compute returns\n",
        "            returns = []\n",
        "            G = 0\n",
        "            for r in reversed(episode_rewards):\n",
        "                G = r + gamma * G\n",
        "                returns.insert(0, G)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Here we update the policy using the collected episode data.\n",
        "            for state, action, G in zip(episode_states, episode_actions, returns):\n",
        "                # Convert the state appropriately. If state was already a sequence,\n",
        "                # convert_state will produce a tensor of shape (1, window_size, feature_dim)\n",
        "                state_tensor = convert_state(state, device)\n",
        "                logits, value, _ = model(state_tensor)\n",
        "                dist = Categorical(logits=logits)\n",
        "\n",
        "                action_tensor = torch.tensor(action, device=device)\n",
        "                log_prob = dist.log_prob(action_tensor)\n",
        "                # Detach value because we don't backpropagate through the advantage\n",
        "                advantage = G - value.squeeze().detach()\n",
        "\n",
        "                policy_loss = -log_prob * advantage\n",
        "                value_loss = F.mse_loss(value.squeeze(), torch.tensor(G, device=device))\n",
        "                (policy_loss + value_loss).backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            net_profit = env.net_worth - env.initial_balance\n",
        "\n",
        "            if net_profit > 0:\n",
        "                wins += 1\n",
        "                tax_liability = 0.25 * net_profit\n",
        "                tax_due = max(tax_liability - tax_credit, 0)\n",
        "                tax_credit = max(tax_credit - tax_liability, 0)\n",
        "            else:\n",
        "                tax_due = 0\n",
        "                tax_credit += abs(net_profit) * 0.25\n",
        "\n",
        "            net_profit_after_tax = net_profit - tax_due\n",
        "            PROFIT += net_profit_after_tax\n",
        "\n",
        "            print(f\"Ticker: {ticker} | Episode {episode+1}/{episodes} | Net PnL: {net_profit:.2f} | Wins: {wins}/{episode+1}\")\n",
        "\n",
        "            if episode % save_interval == 0:\n",
        "                torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "                print(\"Model progress saved.\")\n",
        "\n",
        "        total_reward, actions = evaluate_model(stock_data, model)\n",
        "        plot_evaluation_results(stock_data, actions)\n",
        "\n",
        "    print(\"Training complete.\")\n",
        "    torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "    print(\"Final model saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VPPJh-7am_Bq",
        "outputId": "df191946-a1db-4c90-d1c9-5fa4f799087c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "  No existing model found — initialized new network.\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'Close'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[45], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run training\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain_on_sp500\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[44], line 116\u001b[0m, in \u001b[0;36mtrain_on_sp500\u001b[1;34m(dataset, episodes, batch_size, gamma, lr, save_interval)\u001b[0m\n\u001b[0;32m    113\u001b[0m dist \u001b[38;5;241m=\u001b[39m Categorical(logits\u001b[38;5;241m=\u001b[39mlogits)\n\u001b[0;32m    114\u001b[0m action \u001b[38;5;241m=\u001b[39m dist\u001b[38;5;241m.\u001b[39msample()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m--> 116\u001b[0m next_state, reward, done, _ \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m episode_states\u001b[38;5;241m.\u001b[39mappend(state)\n\u001b[0;32m    119\u001b[0m episode_actions\u001b[38;5;241m.\u001b[39mappend(action)\n",
            "Cell \u001b[1;32mIn[40], line 49\u001b[0m, in \u001b[0;36mTradingEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     47\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     48\u001b[0m reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 49\u001b[0m current_price \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mClose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m action \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# Buy\u001b[39;00m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\shmue\\projects\\python\\open_pojects\\probability_of_market_movment\\.venv\\lib\\site-packages\\pandas\\core\\indexing.py:1183\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1181\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(com\u001b[38;5;241m.\u001b[39mapply_if_callable(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[0;32m   1182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m-> 1183\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_takeable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1186\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\shmue\\projects\\python\\open_pojects\\probability_of_market_movment\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:4214\u001b[0m, in \u001b[0;36mDataFrame._get_value\u001b[1;34m(self, index, col, takeable)\u001b[0m\n\u001b[0;32m   4211\u001b[0m     series \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ixs(col, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   4212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m series\u001b[38;5;241m.\u001b[39m_values[index]\n\u001b[1;32m-> 4214\u001b[0m series \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_item_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4215\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_engine\n\u001b[0;32m   4217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, MultiIndex):\n\u001b[0;32m   4218\u001b[0m     \u001b[38;5;66;03m# CategoricalIndex: Trying to use the engine fastpath may give incorrect\u001b[39;00m\n\u001b[0;32m   4219\u001b[0m     \u001b[38;5;66;03m#  results if our categories are integers that dont match our codes\u001b[39;00m\n\u001b[0;32m   4220\u001b[0m     \u001b[38;5;66;03m# IntervalIndex: IntervalTree has no get_loc\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\shmue\\projects\\python\\open_pojects\\probability_of_market_movment\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:4638\u001b[0m, in \u001b[0;36mDataFrame._get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   4633\u001b[0m res \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mget(item)\n\u001b[0;32m   4634\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4635\u001b[0m     \u001b[38;5;66;03m# All places that call _get_item_cache have unique columns,\u001b[39;00m\n\u001b[0;32m   4636\u001b[0m     \u001b[38;5;66;03m#  pending resolution of GH#33047\u001b[39;00m\n\u001b[1;32m-> 4638\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4639\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ixs(loc, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   4641\u001b[0m     cache[item] \u001b[38;5;241m=\u001b[39m res\n",
            "File \u001b[1;32mc:\\Users\\shmue\\projects\\python\\open_pojects\\probability_of_market_movment\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
            "\u001b[1;31mKeyError\u001b[0m: 'Close'"
          ]
        }
      ],
      "source": [
        "\n",
        "# Run training\n",
        "train_on_sp500(dataset, episodes=10)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
