{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sh20022002/probability_of_change/blob/main/trader_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXajTKy6m_Bl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pickle\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torchrl.envs import EnvBase\n",
        "from tensordict import TensorDict\n",
        "from torchrl.envs.utils import step_mdp\n",
        "from torch.distributions import Categorical\n",
        "from tensordict import TensorDict\n",
        "from torchrl.collectors import SyncDataCollector\n",
        "from torchrl.data import ReplayBuffer, LazyTensorStorage\n",
        "from torchrl.objectives import A2CLoss\n",
        "from tensordict import TensorDictBase\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import  Dataset\n",
        "import torch.optim as optim\n",
        "\n",
        "import collections\n",
        "import warnings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "MODEL_SAVE_PATH = \"trading_model.pth\"\n",
        "SP500_TICKERS = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
        "COLUMNS = ['Open', 'High', 'Low', 'Close', 'Volume']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class StockDataset(Dataset):\n",
        "    def __init__(self, tickers, num_segments=10):\n",
        "        self.tickers = tickers\n",
        "        self.num_segments = num_segments\n",
        "        self.segmented_data = []\n",
        "        self.current_ticker_idx = 0\n",
        "\n",
        "        self._load_and_split_data()\n",
        "\n",
        "    def _load_and_split_data(self):\n",
        "        saved = False\n",
        "        for ticker in self.tickers:\n",
        "            print(f\"Processing ticker: {ticker}\")\n",
        "\n",
        "            try:\n",
        "                stock_data = yf.download(ticker, period='max', progress=False)\n",
        "                if stock_data.empty:\n",
        "                    print(f\"Warning: Empty data for ticker: {ticker}\")\n",
        "                    return None\n",
        "                \n",
        "                df = stock_data[COLUMNS].dropna()\n",
        "                \n",
        "                features_df = df[COLUMNS]\n",
        "                if features_df.empty:\n",
        "                    return None\n",
        "\n",
        "                    \n",
        "                # Select features to scale\n",
        "                features = df[COLUMNS]\n",
        "                scaler = StandardScaler()\n",
        "                scaled_data = scaler.fit_transform(features)\n",
        "\n",
        "                # Save the fitted scaler\n",
        "                if not saved:\n",
        "                    os.makedirs(\"data\", exist_ok=True)\n",
        "                    with open(\"data/scaler.pkl\", \"wb\") as f:\n",
        "                        pickle.dump(scaler, f)\n",
        "\n",
        "            except Exception as e:\n",
        "                        print(f\"Error downloading data for {ticker}: {e}\")\n",
        "                        return None\n",
        "\n",
        "            scaled_values = scaled_data.astype(np.float32).values\n",
        "            segment_size = len(scaled_values) // self.num_segments\n",
        "            for i in range(self.num_segments):\n",
        "                start = i * segment_size\n",
        "                end = (i + 1) * segment_size if i < self.num_segments - 1 else len(scaled_values)\n",
        "                segment = scaled_values[start:end]\n",
        "                if len(segment) > 0:\n",
        "                    self.segmented_data.append((segment, ticker))\n",
        "                    self.current_ticker_idx += 1\n",
        "\n",
        "            \n",
        "    def __len__(self):\n",
        "        return len(self.segmented_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.segmented_data[idx]\n",
        "\n",
        "\n",
        "    def fetch_next_stock(self):\n",
        "        \"\"\"Returns a dataset segment in order, keeping track of stock index.\"\"\"\n",
        "        if not self.segmented_data:\n",
        "            return None, None  # No more stocks\n",
        "\n",
        "        if self.current_ticker_idx >= len(self.segmented_data):\n",
        "            self.current_ticker_idx = 0  # Loop back to start\n",
        "\n",
        "        segment, ticker = self.segmented_data[self.current_ticker_idx]\n",
        "        self.current_ticker_idx += 1\n",
        "        return segment, ticker\n",
        "\n",
        "    def save(self, path):\n",
        "        \"\"\"\n",
        "        Saves the StockDataset to a pickle file.\n",
        "\n",
        "        Args:\n",
        "            filepath (str): The path to the pickle file.\n",
        "        \"\"\"\n",
        "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "        with open(path, 'wb') as f:\n",
        "            pickle.dump(self, f)\n",
        "        print('Saved Dataset.')\n",
        "\n",
        "    @staticmethod\n",
        "    def load(path):\n",
        "        \"\"\"\n",
        "        Loads the StockDataset from a pickle file.\n",
        "\n",
        "        Args:\n",
        "            filepath (str): The path to the pickle file.\n",
        "\n",
        "        Returns:\n",
        "            StockDataset: The loaded StockDataset object.\n",
        "        \"\"\"\n",
        "        with open(path, 'rb') as f:\n",
        "            return pickle.load(f)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TradingEnv(EnvBase):\n",
        "    def __init__(self, df: pd.DataFrame, initial_balance=10000, scaler=None, window_size=30):\n",
        "        super().__init__()\n",
        "\n",
        "        if isinstance(df, np.ndarray):\n",
        "            df = pd.DataFrame(df)\n",
        "\n",
        "        if len(df) < window_size:\n",
        "            raise ValueError(f\"Insufficient data: need at least {window_size} rows, got {len(df)}.\")\n",
        "\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.initial_balance = initial_balance\n",
        "        self.scaler = scaler\n",
        "        self.window_size = window_size\n",
        "\n",
        "        self.action_spec = torch.tensor([4])  # 4 discrete actions\n",
        "        obs_shape = (window_size, df.shape[1] + 2)  # +2 for Balance, NetWorth\n",
        "        self.observation_spec = torch.empty(obs_shape, dtype=torch.float32)\n",
        "\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self, tensordict=None):\n",
        "        self.current_step = self.window_size\n",
        "        self.balance = self.initial_balance\n",
        "        self.net_worth = self.initial_balance\n",
        "        self.positions = []\n",
        "        self.position_type = None\n",
        "        self.trades = []\n",
        "\n",
        "        obs = self._get_observation()\n",
        "        return TensorDict({\"observation\": obs}, batch_size=[])\n",
        "\n",
        "    def _get_observation(self):\n",
        "        frame = self.df.iloc[self.current_step - self.window_size:self.current_step]\n",
        "        obs = frame.copy()\n",
        "        obs['Balance'] = self.balance\n",
        "        obs['NetWorth'] = self.net_worth\n",
        "\n",
        "        try:\n",
        "            if self.scaler is not None:\n",
        "                obs = self.scaler.transform(obs)\n",
        "        except Exception as e:\n",
        "            warnings.warn(f\"Scaler transform failed: {e}. Proceeding without scaling.\")\n",
        "\n",
        "        return torch.tensor(obs.astype(np.float32).values)\n",
        "\n",
        "    def step(self, tensordict):\n",
        "        action = tensordict[\"action\"].item()\n",
        "        reward = 0.0\n",
        "        done = False\n",
        "\n",
        "        current_price = self.df.loc[self.current_step, 'Close']\n",
        "\n",
        "        if action == 0:  # Buy\n",
        "            if self.position_type is None:\n",
        "                self.positions.append(current_price)\n",
        "                self.position_type = 'long'\n",
        "            elif self.position_type == 'short':\n",
        "                entry = self.positions.pop(0)\n",
        "                profit = entry - current_price\n",
        "                reward += profit\n",
        "                self.balance += profit\n",
        "                if not self.positions:\n",
        "                    self.position_type = None\n",
        "\n",
        "        elif action == 1:  # Sell\n",
        "            if self.position_type == 'long':\n",
        "                entry = self.positions.pop(0)\n",
        "                profit = current_price - entry\n",
        "                reward += profit\n",
        "                self.balance += profit\n",
        "                if not self.positions:\n",
        "                    self.position_type = None\n",
        "\n",
        "        elif action == 2:  # Short\n",
        "            if self.position_type is None:\n",
        "                self.positions.append(current_price)\n",
        "                self.position_type = 'short'\n",
        "            elif self.position_type == 'long':\n",
        "                entry = self.positions.pop(0)\n",
        "                profit = current_price - entry\n",
        "                reward += profit\n",
        "                self.balance += profit\n",
        "                if not self.positions:\n",
        "                    self.position_type = None\n",
        "\n",
        "        elif action == 3:  # Cover\n",
        "            if self.position_type == 'short':\n",
        "                entry = self.positions.pop(0)\n",
        "                profit = entry - current_price\n",
        "                reward += profit\n",
        "                self.balance += profit\n",
        "                if not self.positions:\n",
        "                    self.position_type = None\n",
        "\n",
        "        self.net_worth = self.balance\n",
        "        self.trades.append((self.current_step, action, current_price, reward))\n",
        "\n",
        "        self.current_step += 1\n",
        "        if self.current_step >= len(self.df):\n",
        "            done = True\n",
        "\n",
        "        next_obs = self._get_observation()\n",
        "\n",
        "        return step_mdp(\n",
        "            TensorDict({\n",
        "                \"next\": TensorDict({\"observation\": next_obs}, batch_size=[]),\n",
        "                \"reward\": torch.tensor(reward, dtype=torch.float32),\n",
        "                \"done\": torch.tensor(done)\n",
        "            }, batch_size=[])\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model(stock_data, model):\n",
        "    \"\"\"Evaluates the model on stock data and returns total reward.\"\"\"\n",
        "    env = TradingEnv(stock_data)\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "    actions = []\n",
        "\n",
        "    while not done:\n",
        "        with torch.no_grad():\n",
        "            state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0)\n",
        "            logits, value, _ = model(state_tensor)\n",
        "            action = torch.argmax(logits).item()\n",
        "\n",
        "\n",
        "        actions.append(action)\n",
        "        state, reward, done, _ = env.step(action)\n",
        "        total_reward += reward\n",
        "\n",
        "    return total_reward, actions\n",
        "\n",
        "# Function to plot evaluation results\n",
        "def plot_evaluation_results(stock_data, actions):\n",
        "    \"\"\"Plots stock data and overlays model evaluation results.\"\"\"\n",
        "    close_prices = stock_data[:, 3]  # Close prices\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(close_prices, label=\"Close Price\", color='black')\n",
        "\n",
        "    buy_signals = [i for i in range(len(actions)) if actions[i] == 1]\n",
        "    sell_signals = [i for i in range(len(actions)) if actions[i] == 2]\n",
        "\n",
        "    plt.scatter(buy_signals, close_prices[buy_signals], color='green', marker='^', label='Buy')\n",
        "    plt.scatter(sell_signals, close_prices[sell_signals], color='red', marker='v', label='Sell')\n",
        "\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel(\"Stock Price\")\n",
        "    plt.legend()\n",
        "    plt.title(f\"Model Evaluation Results\")\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "UsVD4Tjim_Bp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing ticker: MMM\n",
            "Scaler saved\n",
            "Processing ticker: AOS\n",
            "Processing ticker: ABT\n",
            "Processing ticker: ABBV\n",
            "Processing ticker: ACN\n",
            "Processing ticker: ADBE\n",
            "Processing ticker: AMD\n",
            "Processing ticker: AES\n",
            "Processing ticker: AFL\n",
            "Processing ticker: A\n",
            "Processing ticker: APD\n",
            "Processing ticker: ABNB\n",
            "Processing ticker: AKAM\n",
            "Processing ticker: ALB\n",
            "Processing ticker: ARE\n",
            "Processing ticker: ALGN\n",
            "Processing ticker: ALLE\n",
            "Processing ticker: LNT\n",
            "Processing ticker: ALL\n",
            "Processing ticker: GOOGL\n",
            "Processing ticker: GOOG\n",
            "Processing ticker: MO\n",
            "Processing ticker: AMZN\n",
            "Processing ticker: AMCR\n",
            "Processing ticker: AEE\n",
            "Processing ticker: AEP\n",
            "Processing ticker: AXP\n",
            "Processing ticker: AIG\n",
            "Processing ticker: AMT\n",
            "Processing ticker: AWK\n",
            "Processing ticker: AMP\n",
            "Processing ticker: AME\n",
            "Processing ticker: AMGN\n",
            "Processing ticker: APH\n",
            "Processing ticker: ADI\n",
            "Processing ticker: ANSS\n",
            "Processing ticker: AON\n",
            "Processing ticker: APA\n",
            "Processing ticker: APO\n",
            "Processing ticker: AAPL\n",
            "Processing ticker: AMAT\n",
            "Processing ticker: APTV\n",
            "Processing ticker: ACGL\n",
            "Processing ticker: ADM\n",
            "Processing ticker: ANET\n",
            "Processing ticker: AJG\n",
            "Processing ticker: AIZ\n",
            "Processing ticker: T\n",
            "Processing ticker: ATO\n",
            "Processing ticker: ADSK\n",
            "Processing ticker: ADP\n",
            "Processing ticker: AZO\n",
            "Processing ticker: AVB\n",
            "Processing ticker: AVY\n",
            "Processing ticker: AXON\n",
            "Processing ticker: BKR\n",
            "Processing ticker: BALL\n",
            "Processing ticker: BAC\n",
            "Processing ticker: BAX\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "1 Failed download:\n",
            "['BRK.B']: YFTzMissingError('possibly delisted; no timezone found')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing ticker: BDX\n",
            "Warning: Empty data for ticker: BRK.B\n",
            "Processing ticker: BBY\n",
            "Processing ticker: TECH\n",
            "Processing ticker: BIIB\n",
            "Processing ticker: BLK\n",
            "Processing ticker: BX\n",
            "Processing ticker: BK\n",
            "Processing ticker: BA\n",
            "Processing ticker: BKNG\n",
            "Processing ticker: BSX\n",
            "Processing ticker: BMY\n",
            "Processing ticker: AVGO\n",
            "Processing ticker: BR\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "1 Failed download:\n",
            "['BF.B']: YFPricesMissingError('possibly delisted; no price data found  (1d 1926-05-11 -> 2025-04-16)')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing ticker: BRO\n",
            "Warning: Empty data for ticker: BF.B\n",
            "Processing ticker: BLDR\n",
            "Processing ticker: BG\n",
            "Processing ticker: BXP\n",
            "Processing ticker: CHRW\n",
            "Processing ticker: CDNS\n",
            "Processing ticker: CZR\n",
            "Processing ticker: CPT\n",
            "Processing ticker: CPB\n",
            "Processing ticker: COF\n",
            "Processing ticker: CAH\n",
            "Processing ticker: KMX\n",
            "Processing ticker: CCL\n",
            "Processing ticker: CARR\n",
            "Processing ticker: CAT\n",
            "Processing ticker: CBOE\n",
            "Processing ticker: CBRE\n",
            "Processing ticker: CDW\n",
            "Processing ticker: COR\n",
            "Processing ticker: CNC\n",
            "Processing ticker: CNP\n",
            "Processing ticker: CF\n",
            "Processing ticker: CRL\n",
            "Processing ticker: SCHW\n",
            "Processing ticker: CHTR\n",
            "Processing ticker: CVX\n",
            "Processing ticker: CMG\n",
            "Processing ticker: CB\n",
            "Processing ticker: CHD\n",
            "Processing ticker: CI\n",
            "Processing ticker: CINF\n",
            "Processing ticker: CTAS\n",
            "Processing ticker: CSCO\n",
            "Processing ticker: C\n",
            "Processing ticker: CFG\n",
            "Processing ticker: CLX\n",
            "Processing ticker: CME\n",
            "Processing ticker: CMS\n",
            "Processing ticker: KO\n",
            "Processing ticker: CTSH\n",
            "Processing ticker: CL\n",
            "Processing ticker: CMCSA\n",
            "Processing ticker: CAG\n",
            "Processing ticker: COP\n",
            "Processing ticker: ED\n",
            "Processing ticker: STZ\n",
            "Processing ticker: CEG\n",
            "Processing ticker: COO\n",
            "Processing ticker: CPRT\n",
            "Processing ticker: GLW\n",
            "Processing ticker: CPAY\n",
            "Processing ticker: CTVA\n",
            "Processing ticker: CSGP\n",
            "Processing ticker: COST\n",
            "Processing ticker: CTRA\n",
            "Processing ticker: CRWD\n",
            "Processing ticker: CCI\n",
            "Processing ticker: CSX\n",
            "Processing ticker: CMI\n",
            "Processing ticker: CVS\n",
            "Processing ticker: DHR\n",
            "Processing ticker: DRI\n",
            "Processing ticker: DVA\n",
            "Processing ticker: DAY\n",
            "Processing ticker: DECK\n",
            "Processing ticker: DE\n",
            "Processing ticker: DELL\n",
            "Processing ticker: DAL\n",
            "Processing ticker: DVN\n",
            "Processing ticker: DXCM\n",
            "Processing ticker: FANG\n",
            "Processing ticker: DLR\n",
            "Processing ticker: DFS\n",
            "Processing ticker: DG\n",
            "Processing ticker: DLTR\n",
            "Processing ticker: D\n",
            "Processing ticker: DPZ\n",
            "Processing ticker: DASH\n",
            "Processing ticker: DOV\n",
            "Processing ticker: DOW\n",
            "Processing ticker: DHI\n",
            "Processing ticker: DTE\n",
            "Processing ticker: DUK\n",
            "Processing ticker: DD\n",
            "Processing ticker: EMN\n",
            "Processing ticker: ETN\n",
            "Processing ticker: EBAY\n",
            "Processing ticker: ECL\n",
            "Processing ticker: EIX\n",
            "Processing ticker: EW\n",
            "Processing ticker: EA\n",
            "Processing ticker: ELV\n",
            "Processing ticker: EMR\n",
            "Processing ticker: ENPH\n",
            "Processing ticker: ETR\n",
            "Processing ticker: EOG\n",
            "Processing ticker: EPAM\n",
            "Processing ticker: EQT\n",
            "Processing ticker: EFX\n",
            "Processing ticker: EQIX\n",
            "Processing ticker: EQR\n",
            "Processing ticker: ERIE\n",
            "Processing ticker: ESS\n",
            "Processing ticker: EL\n",
            "Processing ticker: EG\n",
            "Processing ticker: EVRG\n",
            "Processing ticker: ES\n",
            "Processing ticker: EXC\n",
            "Processing ticker: EXE\n",
            "Processing ticker: EXPE\n",
            "Processing ticker: EXPD\n",
            "Processing ticker: EXR\n",
            "Processing ticker: XOM\n",
            "Processing ticker: FFIV\n",
            "Processing ticker: FDS\n",
            "Processing ticker: FICO\n",
            "Processing ticker: FAST\n",
            "Processing ticker: FRT\n",
            "Processing ticker: FDX\n",
            "Processing ticker: FIS\n",
            "Processing ticker: FITB\n",
            "Processing ticker: FSLR\n",
            "Processing ticker: FE\n",
            "Processing ticker: FI\n",
            "Processing ticker: F\n",
            "Processing ticker: FTNT\n",
            "Processing ticker: FTV\n",
            "Processing ticker: FOXA\n",
            "Processing ticker: FOX\n",
            "Processing ticker: BEN\n",
            "Processing ticker: FCX\n",
            "Processing ticker: GRMN\n",
            "Processing ticker: IT\n",
            "Processing ticker: GE\n",
            "Processing ticker: GEHC\n",
            "Processing ticker: GEV\n",
            "Processing ticker: GEN\n",
            "Processing ticker: GNRC\n",
            "Processing ticker: GD\n",
            "Processing ticker: GIS\n",
            "Processing ticker: GM\n",
            "Processing ticker: GPC\n",
            "Processing ticker: GILD\n",
            "Processing ticker: GPN\n",
            "Processing ticker: GL\n",
            "Processing ticker: GDDY\n",
            "Processing ticker: GS\n",
            "Processing ticker: HAL\n",
            "Processing ticker: HIG\n",
            "Processing ticker: HAS\n",
            "Processing ticker: HCA\n",
            "Processing ticker: DOC\n",
            "Processing ticker: HSIC\n",
            "Processing ticker: HSY\n",
            "Processing ticker: HES\n",
            "Processing ticker: HPE\n",
            "Processing ticker: HLT\n",
            "Processing ticker: HOLX\n",
            "Processing ticker: HD\n",
            "Processing ticker: HON\n",
            "Processing ticker: HRL\n",
            "Processing ticker: HST\n",
            "Processing ticker: HWM\n",
            "Processing ticker: HPQ\n",
            "Processing ticker: HUBB\n",
            "Processing ticker: HUM\n",
            "Processing ticker: HBAN\n",
            "Processing ticker: HII\n",
            "Processing ticker: IBM\n",
            "Processing ticker: IEX\n",
            "Processing ticker: IDXX\n",
            "Processing ticker: ITW\n",
            "Processing ticker: INCY\n",
            "Processing ticker: IR\n",
            "Processing ticker: PODD\n",
            "Processing ticker: INTC\n",
            "Processing ticker: ICE\n",
            "Processing ticker: IFF\n",
            "Processing ticker: IP\n",
            "Processing ticker: IPG\n",
            "Processing ticker: INTU\n",
            "Processing ticker: ISRG\n",
            "Processing ticker: IVZ\n",
            "Processing ticker: INVH\n",
            "Processing ticker: IQV\n",
            "Processing ticker: IRM\n",
            "Processing ticker: JBHT\n",
            "Processing ticker: JBL\n",
            "Processing ticker: JKHY\n",
            "Processing ticker: J\n",
            "Processing ticker: JNJ\n",
            "Processing ticker: JCI\n",
            "Processing ticker: JPM\n",
            "Processing ticker: JNPR\n",
            "Processing ticker: K\n",
            "Processing ticker: KVUE\n",
            "Processing ticker: KDP\n",
            "Processing ticker: KEY\n",
            "Processing ticker: KEYS\n",
            "Processing ticker: KMB\n",
            "Processing ticker: KIM\n",
            "Processing ticker: KMI\n",
            "Processing ticker: KKR\n",
            "Processing ticker: KLAC\n",
            "Processing ticker: KHC\n",
            "Processing ticker: KR\n",
            "Processing ticker: LHX\n",
            "Processing ticker: LH\n",
            "Processing ticker: LRCX\n",
            "Processing ticker: LW\n",
            "Processing ticker: LVS\n",
            "Processing ticker: LDOS\n",
            "Processing ticker: LEN\n",
            "Processing ticker: LII\n",
            "Processing ticker: LLY\n",
            "Processing ticker: LIN\n",
            "Processing ticker: LYV\n",
            "Processing ticker: LKQ\n",
            "Processing ticker: LMT\n",
            "Processing ticker: L\n",
            "Processing ticker: LOW\n",
            "Processing ticker: LULU\n",
            "Processing ticker: LYB\n",
            "Processing ticker: MTB\n",
            "Processing ticker: MPC\n",
            "Processing ticker: MKTX\n",
            "Processing ticker: MAR\n",
            "Processing ticker: MMC\n",
            "Processing ticker: MLM\n",
            "Processing ticker: MAS\n",
            "Processing ticker: MA\n",
            "Processing ticker: MTCH\n",
            "Processing ticker: MKC\n",
            "Processing ticker: MCD\n",
            "Processing ticker: MCK\n",
            "Processing ticker: MDT\n",
            "Processing ticker: MRK\n",
            "Processing ticker: META\n",
            "Processing ticker: MET\n",
            "Processing ticker: MTD\n",
            "Processing ticker: MGM\n",
            "Processing ticker: MCHP\n",
            "Processing ticker: MU\n",
            "Processing ticker: MSFT\n",
            "Processing ticker: MAA\n",
            "Processing ticker: MRNA\n",
            "Processing ticker: MHK\n",
            "Processing ticker: MOH\n",
            "Processing ticker: TAP\n",
            "Processing ticker: MDLZ\n",
            "Processing ticker: MPWR\n",
            "Processing ticker: MNST\n",
            "Processing ticker: MCO\n",
            "Processing ticker: MS\n",
            "Processing ticker: MOS\n",
            "Processing ticker: MSI\n",
            "Processing ticker: MSCI\n",
            "Processing ticker: NDAQ\n",
            "Processing ticker: NTAP\n",
            "Processing ticker: NFLX\n",
            "Processing ticker: NEM\n",
            "Processing ticker: NWSA\n",
            "Processing ticker: NWS\n",
            "Processing ticker: NEE\n",
            "Processing ticker: NKE\n",
            "Processing ticker: NI\n",
            "Processing ticker: NDSN\n",
            "Processing ticker: NSC\n",
            "Processing ticker: NTRS\n",
            "Processing ticker: NOC\n",
            "Processing ticker: NCLH\n",
            "Processing ticker: NRG\n",
            "Processing ticker: NUE\n",
            "Processing ticker: NVDA\n",
            "Processing ticker: NVR\n",
            "Processing ticker: NXPI\n",
            "Processing ticker: ORLY\n",
            "Processing ticker: OXY\n",
            "Processing ticker: ODFL\n",
            "Processing ticker: OMC\n",
            "Processing ticker: ON\n",
            "Processing ticker: OKE\n",
            "Processing ticker: ORCL\n",
            "Processing ticker: OTIS\n",
            "Processing ticker: PCAR\n",
            "Processing ticker: PKG\n",
            "Processing ticker: PLTR\n",
            "Processing ticker: PANW\n",
            "Processing ticker: PARA\n",
            "Processing ticker: PH\n",
            "Processing ticker: PAYX\n",
            "Processing ticker: PAYC\n",
            "Processing ticker: PYPL\n",
            "Processing ticker: PNR\n",
            "Processing ticker: PEP\n",
            "Processing ticker: PFE\n",
            "Processing ticker: PCG\n",
            "Processing ticker: PM\n",
            "Processing ticker: PSX\n",
            "Processing ticker: PNW\n",
            "Processing ticker: PNC\n",
            "Processing ticker: POOL\n",
            "Processing ticker: PPG\n",
            "Processing ticker: PPL\n",
            "Processing ticker: PFG\n",
            "Processing ticker: PG\n",
            "Processing ticker: PGR\n",
            "Processing ticker: PLD\n",
            "Processing ticker: PRU\n",
            "Processing ticker: PEG\n",
            "Processing ticker: PTC\n",
            "Processing ticker: PSA\n",
            "Processing ticker: PHM\n",
            "Processing ticker: PWR\n",
            "Processing ticker: QCOM\n",
            "Processing ticker: DGX\n",
            "Processing ticker: RL\n",
            "Processing ticker: RJF\n",
            "Processing ticker: RTX\n",
            "Processing ticker: O\n",
            "Processing ticker: REG\n",
            "Processing ticker: REGN\n",
            "Processing ticker: RF\n",
            "Processing ticker: RSG\n",
            "Processing ticker: RMD\n",
            "Processing ticker: RVTY\n",
            "Processing ticker: ROK\n",
            "Processing ticker: ROL\n",
            "Processing ticker: ROP\n",
            "Processing ticker: ROST\n",
            "Processing ticker: RCL\n",
            "Processing ticker: SPGI\n",
            "Processing ticker: CRM\n",
            "Processing ticker: SBAC\n",
            "Processing ticker: SLB\n",
            "Processing ticker: STX\n",
            "Processing ticker: SRE\n",
            "Processing ticker: NOW\n",
            "Processing ticker: SHW\n",
            "Processing ticker: SPG\n",
            "Processing ticker: SWKS\n",
            "Processing ticker: SJM\n",
            "Processing ticker: SW\n",
            "Processing ticker: SNA\n",
            "Processing ticker: SOLV\n",
            "Processing ticker: SO\n",
            "Processing ticker: LUV\n",
            "Processing ticker: SWK\n",
            "Processing ticker: SBUX\n",
            "Processing ticker: STT\n",
            "Processing ticker: STLD\n",
            "Processing ticker: STE\n",
            "Processing ticker: SYK\n",
            "Processing ticker: SMCI\n",
            "Processing ticker: SYF\n",
            "Processing ticker: SNPS\n",
            "Processing ticker: SYY\n",
            "Processing ticker: TMUS\n",
            "Processing ticker: TROW\n",
            "Processing ticker: TTWO\n",
            "Processing ticker: TPR\n",
            "Processing ticker: TRGP\n",
            "Processing ticker: TGT\n",
            "Processing ticker: TEL\n",
            "Processing ticker: TDY\n",
            "Processing ticker: TER\n",
            "Processing ticker: TSLA\n",
            "Processing ticker: TXN\n",
            "Processing ticker: TPL\n",
            "Processing ticker: TXT\n",
            "Processing ticker: TMO\n",
            "Processing ticker: TJX\n",
            "Processing ticker: TKO\n",
            "Processing ticker: TSCO\n",
            "Processing ticker: TT\n",
            "Processing ticker: TDG\n",
            "Processing ticker: TRV\n",
            "Processing ticker: TRMB\n",
            "Processing ticker: TFC\n",
            "Processing ticker: TYL\n",
            "Processing ticker: TSN\n",
            "Processing ticker: USB\n",
            "Processing ticker: UBER\n",
            "Processing ticker: UDR\n",
            "Processing ticker: ULTA\n",
            "Processing ticker: UNP\n",
            "Processing ticker: UAL\n",
            "Processing ticker: UPS\n",
            "Processing ticker: URI\n",
            "Processing ticker: UNH\n",
            "Processing ticker: UHS\n",
            "Processing ticker: VLO\n",
            "Processing ticker: VTR\n",
            "Processing ticker: VLTO\n",
            "Processing ticker: VRSN\n",
            "Processing ticker: VRSK\n",
            "Processing ticker: VZ\n",
            "Processing ticker: VRTX\n",
            "Processing ticker: VTRS\n",
            "Processing ticker: VICI\n",
            "Processing ticker: V\n",
            "Processing ticker: VST\n",
            "Processing ticker: VMC\n",
            "Processing ticker: WRB\n",
            "Processing ticker: GWW\n",
            "Processing ticker: WAB\n",
            "Processing ticker: WBA\n",
            "Processing ticker: WMT\n",
            "Processing ticker: DIS\n",
            "Processing ticker: WBD\n",
            "Processing ticker: WM\n",
            "Processing ticker: WAT\n",
            "Processing ticker: WEC\n",
            "Processing ticker: WFC\n",
            "Processing ticker: WELL\n",
            "Processing ticker: WST\n",
            "Processing ticker: WDC\n",
            "Processing ticker: WY\n",
            "Processing ticker: WSM\n",
            "Processing ticker: WMB\n",
            "Processing ticker: WTW\n",
            "Processing ticker: WDAY\n",
            "Processing ticker: WYNN\n",
            "Processing ticker: XEL\n",
            "Processing ticker: XYL\n",
            "Processing ticker: YUM\n",
            "Processing ticker: ZBRA\n",
            "Processing ticker: ZBH\n",
            "Processing ticker: ZTS\n",
            "Saved Dataset.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if os.path.exists(\"data/stock_dataset.pkl\"):\n",
        "    dataset = StockDataset.load(\"data/stock_dataset.pkl\")\n",
        "else:\n",
        "    tickers = pd.read_html(SP500_TICKERS)[0]['Symbol'].tolist()\n",
        "    dataset = StockDataset(tickers, num_segments=10)\n",
        "    dataset.save(\"data/stock_dataset.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class StockLSTM(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=128, lstm_layers=2, fc_dim=64, output_dim=4):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.lstm_layers = lstm_layers\n",
        "\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, lstm_layers, batch_first=True, dropout=0.2 if lstm_layers > 1 else 0.0)\n",
        "        self.norm = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "        self.actor = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, fc_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(fc_dim, output_dim)\n",
        "        )\n",
        "\n",
        "        self.critic = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, fc_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(fc_dim, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, tensordict: TensorDictBase):\n",
        "        obs = tensordict[\"observation\"]  # Shape: (B, T, input_dim)\n",
        "\n",
        "        if obs.ndim == 2:\n",
        "            obs = obs.unsqueeze(0)\n",
        "\n",
        "        # Get sequence lengths or default to full length\n",
        "        lengths = tensordict.get(\"lengths\", torch.full((obs.size(0),), obs.size(1), dtype=torch.long, device=obs.device))\n",
        "\n",
        "        # Pack padded sequences for LSTM\n",
        "        packed = pack_padded_sequence(obs, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "        packed_out, _ = self.lstm(packed)\n",
        "        lstm_out, _ = pad_packed_sequence(packed_out, batch_first=True)\n",
        "\n",
        "        # Gather last output per sequence (according to actual length)\n",
        "        idx = (lengths - 1).view(-1, 1, 1).expand(-1, 1, self.hidden_dim)\n",
        "        last_out = lstm_out.gather(1, idx).squeeze(1)  # Shape: (B, hidden_dim)\n",
        "\n",
        "        last_out = self.norm(last_out)\n",
        "\n",
        "        logits = self.actor(last_out)\n",
        "        value = self.critic(last_out)\n",
        "\n",
        "        tensordict.set(\"logits\", logits)\n",
        "        tensordict.set(\"value\", value)\n",
        "        return tensordict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def init_or_load(input_dim: int = 7,\n",
        "                     output_dim: int = 3,\n",
        "                     lr: float = 1e-3,\n",
        "                     memory_size: int = 10_000):\n",
        "    \"\"\"\n",
        "    Returns (model, optimizer, memory), loading pretrained weights if available.\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Using device:\", device)\n",
        "\n",
        "    model = StockLSTM(input_dim=input_dim, output_dim=output_dim).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    memory = collections.deque(maxlen=memory_size)\n",
        "\n",
        "    if os.path.exists(MODEL_SAVE_PATH):\n",
        "        model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
        "        print(f\" Loaded existing model from {MODEL_SAVE_PATH}\")\n",
        "    else:\n",
        "        print(\"  No existing model found — initialized new network.\")\n",
        "\n",
        "    return model, optimizer, memory, device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def convert_state(state):\n",
        "    if isinstance(state, np.ndarray):\n",
        "        state = torch.tensor(state, dtype=torch.float32)\n",
        "    if isinstance(state, list):\n",
        "        state = torch.tensor(state, dtype=torch.float32)\n",
        "    if state.ndim == 2:\n",
        "        state = state.unsqueeze(0)\n",
        "    return state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def train(dataset, episodes=10, gamma=0.95, lr=1e-3):\n",
        "    model, optimizer, _, device = init_or_load(input_dim=7, output_dim=4, lr=lr)\n",
        "    model.to(device)\n",
        "\n",
        "    if os.path.exists(MODEL_SAVE_PATH):\n",
        "        model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
        "        print(\"Loaded existing model.\")\n",
        "\n",
        "    window_size = 7\n",
        "\n",
        "    while True:\n",
        "        stock_data, ticker = dataset.fetch_next_stock()\n",
        "        if stock_data is None:\n",
        "            print(\"All data segments processed, restarting training loop...\")\n",
        "            break\n",
        "\n",
        "        if isinstance(stock_data, np.ndarray):\n",
        "            stock_data = pd.DataFrame(stock_data)\n",
        "\n",
        "        if len(stock_data) < window_size:\n",
        "            print(f\"Skipping stock {ticker}: only {len(stock_data)} rows (<{window_size}).\")\n",
        "            continue\n",
        "\n",
        "        env = TradingEnv(stock_data, window_size=window_size)\n",
        "\n",
        "        collector = SyncDataCollector(\n",
        "            create_env_fn=lambda: env,\n",
        "            policy=lambda td: TensorDict({\"action\": Categorical(logits=model(td[\"observation\"]))}, batch_size=[]),\n",
        "            frames_per_batch=episodes,\n",
        "            total_frames=episodes\n",
        "        )\n",
        "\n",
        "        loss_module = A2CLoss(model, gamma=gamma)\n",
        "\n",
        "        buffer = ReplayBuffer(storage=LazyTensorStorage(max_size=episodes))\n",
        "\n",
        "        for i, tensordict_data in enumerate(collector):\n",
        "            buffer.extend(tensordict_data)\n",
        "\n",
        "            sampled_data = buffer.sample(batch_size=episodes)\n",
        "\n",
        "            loss_td = loss_module(sampled_data)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss_td[\"loss\"].backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            print(f\"[{ticker}] Episode {i+1}/{episodes} | Loss: {loss_td['loss'].item():.4f}\")\n",
        "\n",
        "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "        print(f\"[{ticker}] Training complete and model saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VPPJh-7am_Bq",
        "outputId": "df191946-a1db-4c90-d1c9-5fa4f799087c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "  No existing model found — initialized new network.\n",
            "RangeIndex(start=0, stop=5, step=1)\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'Close'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run training\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain_on_sp500\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[26], line 116\u001b[0m, in \u001b[0;36mtrain_on_sp500\u001b[1;34m(dataset, episodes, batch_size, gamma, lr, save_interval)\u001b[0m\n\u001b[0;32m    113\u001b[0m dist \u001b[38;5;241m=\u001b[39m Categorical(logits\u001b[38;5;241m=\u001b[39mlogits)\n\u001b[0;32m    114\u001b[0m action \u001b[38;5;241m=\u001b[39m dist\u001b[38;5;241m.\u001b[39msample()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m--> 116\u001b[0m next_state, reward, done, _ \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m episode_states\u001b[38;5;241m.\u001b[39mappend(state)\n\u001b[0;32m    119\u001b[0m episode_actions\u001b[38;5;241m.\u001b[39mappend(action)\n",
            "Cell \u001b[1;32mIn[22], line 50\u001b[0m, in \u001b[0;36mTradingEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     48\u001b[0m reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m---> 50\u001b[0m current_price \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mClose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;66;03m#?\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m action \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# Buy\u001b[39;00m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\shmue\\projects\\python\\open_pojects\\probability_of_market_movment\\.venv\\lib\\site-packages\\pandas\\core\\indexing.py:1183\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1181\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(com\u001b[38;5;241m.\u001b[39mapply_if_callable(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[0;32m   1182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m-> 1183\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_takeable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1186\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\shmue\\projects\\python\\open_pojects\\probability_of_market_movment\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:4214\u001b[0m, in \u001b[0;36mDataFrame._get_value\u001b[1;34m(self, index, col, takeable)\u001b[0m\n\u001b[0;32m   4211\u001b[0m     series \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ixs(col, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   4212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m series\u001b[38;5;241m.\u001b[39m_values[index]\n\u001b[1;32m-> 4214\u001b[0m series \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_item_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4215\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_engine\n\u001b[0;32m   4217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, MultiIndex):\n\u001b[0;32m   4218\u001b[0m     \u001b[38;5;66;03m# CategoricalIndex: Trying to use the engine fastpath may give incorrect\u001b[39;00m\n\u001b[0;32m   4219\u001b[0m     \u001b[38;5;66;03m#  results if our categories are integers that dont match our codes\u001b[39;00m\n\u001b[0;32m   4220\u001b[0m     \u001b[38;5;66;03m# IntervalIndex: IntervalTree has no get_loc\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\shmue\\projects\\python\\open_pojects\\probability_of_market_movment\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:4638\u001b[0m, in \u001b[0;36mDataFrame._get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   4633\u001b[0m res \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mget(item)\n\u001b[0;32m   4634\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4635\u001b[0m     \u001b[38;5;66;03m# All places that call _get_item_cache have unique columns,\u001b[39;00m\n\u001b[0;32m   4636\u001b[0m     \u001b[38;5;66;03m#  pending resolution of GH#33047\u001b[39;00m\n\u001b[1;32m-> 4638\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4639\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ixs(loc, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   4641\u001b[0m     cache[item] \u001b[38;5;241m=\u001b[39m res\n",
            "File \u001b[1;32mc:\\Users\\shmue\\projects\\python\\open_pojects\\probability_of_market_movment\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
            "\u001b[1;31mKeyError\u001b[0m: 'Close'"
          ]
        }
      ],
      "source": [
        "\n",
        "# Run training\n",
        "train(dataset, episodes=10)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
