{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sh20022002/probability_of_change/blob/main/trader_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "metadata": {
        "id": "QXajTKy6m_Bl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pickle\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import gym\n",
        "from gym import spaces\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Categorical\n",
        "\n",
        "import random\n",
        "import collections\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 279,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "MODEL_SAVE_PATH = \"trading_model.pth\"\n",
        "SP500_TICKERS = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
        "\n",
        "\n",
        "class StockDataset:\n",
        "    def __init__(self, tickers, num_segments=10):\n",
        "        self.tickers = tickers\n",
        "        self.num_segments = num_segments  # Number of parts to divide the dataset into\n",
        "        self.segmented_data = []  # Preprocessed data\n",
        "        self.current_ticker_idx = 0  # Keep track of which stock is being processed\n",
        "\n",
        "        self._load_and_split_data()\n",
        "\n",
        "    def _load_and_split_data(self):\n",
        "        \"\"\"Loads full dataset once and splits into shuffled segments\"\"\"\n",
        "        scaler_saved = False\n",
        "        scaler = None\n",
        "\n",
        "        for ticker in self.tickers:\n",
        "            try:\n",
        "                stock_data = yf.download(ticker, period='max', progress=False)\n",
        "                if stock_data.empty:\n",
        "                    print(f\"Warning: Empty data for ticker: {ticker}\")\n",
        "                    continue\n",
        "\n",
        "                df = stock_data[['Open', 'High', 'Low', 'Close', 'Volume']].dropna()\n",
        "                df['Return'] = df['Close'].pct_change()\n",
        "                df['SMA150'] = df['Close'].rolling(window=150).mean()\n",
        "                df.dropna(inplace=True)\n",
        "\n",
        "                features_df = df[['Open', 'Close', 'Return', 'Volume', 'SMA150']]\n",
        "                if features_df.empty:\n",
        "                    continue\n",
        "\n",
        "                print(f\"Processing ticker: {ticker}\")\n",
        "\n",
        "                variances = features_df.var()\n",
        "                features_df = features_df[[col for col in features_df.columns if variances[col] != 0]]\n",
        "\n",
        "                if scaler is None:\n",
        "                    scaler = StandardScaler().fit(features_df)\n",
        "\n",
        "                columns = features_df.columns\n",
        "                index = features_df.index\n",
        "\n",
        "                features_df = pd.DataFrame(\n",
        "                    scaler.transform(features_df),\n",
        "                    columns=columns,\n",
        "                    index=index\n",
        "                )\n",
        "\n",
        "                scaled_values = features_df.astype(np.float32).values\n",
        "                segment_size = len(scaled_values) // self.num_segments\n",
        "                segments = [scaled_values[i * segment_size:(i + 1) * segment_size] for i in range(self.num_segments)]\n",
        "                self.segmented_data.extend([(segment, ticker) for segment in segments])\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error downloading data for {ticker}: {e}\")\n",
        "                continue\n",
        "\n",
        "        if scaler is not None and not scaler_saved:\n",
        "            os.makedirs(\"data\", exist_ok=True)\n",
        "            with open(\"data/scaler.pkl\", \"wb\") as f:\n",
        "                pickle.dump(scaler, f)\n",
        "            print(\"Scaler saved\")\n",
        "\n",
        "    def fetch_next_stock(self):\n",
        "        \"\"\"Returns a dataset segment in order, keeping track of stock index.\"\"\"\n",
        "        if not self.segmented_data:\n",
        "            return None, None  # No more stocks\n",
        "\n",
        "        if self.current_ticker_idx >= len(self.segmented_data):\n",
        "            self.current_ticker_idx = 0  # Loop back to start\n",
        "\n",
        "        segment, ticker = self.segmented_data[self.current_ticker_idx]\n",
        "        self.current_ticker_idx += 1\n",
        "        return segment, ticker\n",
        "\n",
        "    def save(self, path):\n",
        "        \"\"\"\n",
        "        Saves the StockDataset to a pickle file.\n",
        "\n",
        "        Args:\n",
        "            filepath (str): The path to the pickle file.\n",
        "        \"\"\"\n",
        "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "        with open(path, 'wb') as f:\n",
        "            pickle.dump(self, f)\n",
        "        print('Saved Dataset.')\n",
        "\n",
        "    @staticmethod\n",
        "    def load(path):\n",
        "        \"\"\"\n",
        "        Loads the StockDataset from a pickle file.\n",
        "\n",
        "        Args:\n",
        "            filepath (str): The path to the pickle file.\n",
        "\n",
        "        Returns:\n",
        "            StockDataset: The loaded StockDataset object.\n",
        "        \"\"\"\n",
        "        with open(path, 'rb') as f:\n",
        "            return pickle.load(f)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Cell 2: Preprocess Data\n",
        "def preprocess_data(df):\n",
        "    \"\"\"Preprocesses stock data by adding features and scaling.\"\"\"\n",
        "    df['Return'] = df['Close'].pct_change()\n",
        "    df['SMA150'] = df['Close'].rolling(window=150).mean()\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    # Select features to scale\n",
        "    features = df[['Open', 'Close', 'Return', 'Volume', 'SMA150']]\n",
        "    scaler = StandardScaler()\n",
        "    scaled_data = scaler.fit_transform(features)\n",
        "\n",
        "    # Save the fitted scaler\n",
        "\n",
        "    os.makedirs(\"data\", exist_ok=True)\n",
        "    with open(\"data/scaler.pkl\", \"wb\") as f:\n",
        "        pickle.dump(scaler, f)\n",
        "\n",
        "    return scaled_data, scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 281,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TradingEnv(gym.Env):\n",
        "    def __init__(self, df, initial_balance=10000, scaler=None, window_size=30):\n",
        "        super(TradingEnv, self).__init__()\n",
        "\n",
        "        if isinstance(df, np.ndarray):\n",
        "            df = pd.DataFrame(df)\n",
        "\n",
        "        if len(df) < window_size:\n",
        "            raise ValueError(f\"Insufficient data: need at least {window_size} rows, got {len(df)}.\")\n",
        "\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.initial_balance = initial_balance\n",
        "        self.scaler = scaler\n",
        "        self.window_size = window_size\n",
        "        self.action_space = spaces.Discrete(4)\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=-np.inf, high=np.inf, \n",
        "            shape=(window_size, df.shape[1] + 2), \n",
        "            dtype=np.float32\n",
        "        )\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_step = self.window_size\n",
        "        self.balance = self.initial_balance\n",
        "        self.net_worth = self.initial_balance\n",
        "        self.positions = []\n",
        "        self.position_type = None\n",
        "        self.trades = []\n",
        "        return self._get_observation()\n",
        "\n",
        "    def _get_observation(self):\n",
        "        frame = self.df.iloc[self.current_step - self.window_size:self.current_step]\n",
        "        obs = frame.copy()\n",
        "        obs['Balance'] = self.balance\n",
        "        obs['NetWorth'] = self.net_worth\n",
        "\n",
        "        try:\n",
        "            if self.scaler is not None:\n",
        "                obs = self.scaler.transform(obs)\n",
        "        except Exception as e:\n",
        "            warnings.warn(f\"Scaler transform failed: {e}. Proceeding without scaling.\")\n",
        "\n",
        "        return obs.astype(np.float32)\n",
        "\n",
        "    def step(self, action):\n",
        "        done = False\n",
        "        reward = 0\n",
        "        current_price = self.df.loc[self.current_step, 'Close']\n",
        "\n",
        "        if action == 0:  # Buy\n",
        "            if self.position_type is None:\n",
        "                self.positions.append(current_price)\n",
        "                self.position_type = 'long'\n",
        "            elif self.position_type == 'short':\n",
        "                entry = self.positions.pop(0)\n",
        "                profit = entry - current_price\n",
        "                reward += profit\n",
        "                self.balance += profit\n",
        "                if not self.positions:\n",
        "                    self.position_type = None\n",
        "\n",
        "        elif action == 1:  # Sell\n",
        "            if self.position_type == 'long':\n",
        "                entry = self.positions.pop(0)\n",
        "                profit = current_price - entry\n",
        "                reward += profit\n",
        "                self.balance += profit\n",
        "                if not self.positions:\n",
        "                    self.position_type = None\n",
        "\n",
        "        elif action == 2:  # Short\n",
        "            if self.position_type is None:\n",
        "                self.positions.append(current_price)\n",
        "                self.position_type = 'short'\n",
        "            elif self.position_type == 'long':\n",
        "                entry = self.positions.pop(0)\n",
        "                profit = current_price - entry\n",
        "                reward += profit\n",
        "                self.balance += profit\n",
        "                if not self.positions:\n",
        "                    self.position_type = None\n",
        "\n",
        "        elif action == 3:  # Cover\n",
        "            if self.position_type == 'short':\n",
        "                entry = self.positions.pop(0)\n",
        "                profit = entry - current_price\n",
        "                reward += profit\n",
        "                self.balance += profit\n",
        "                if not self.positions:\n",
        "                    self.position_type = None\n",
        "\n",
        "        self.net_worth = self.balance\n",
        "        self.trades.append((self.current_step, action, current_price, reward))\n",
        "\n",
        "        self.current_step += 1\n",
        "        if self.current_step >= len(self.df):\n",
        "            done = True\n",
        "\n",
        "        return self._get_observation(), reward, done, {}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 282,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model(stock_data, model):\n",
        "    \"\"\"Evaluates the model on stock data and returns total reward.\"\"\"\n",
        "    env = TradingEnv(stock_data)\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "    actions = []\n",
        "\n",
        "    while not done:\n",
        "        with torch.no_grad():\n",
        "            state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0)\n",
        "            logits, value, _ = model(state_tensor)\n",
        "            action = torch.argmax(logits).item()\n",
        "\n",
        "\n",
        "        actions.append(action)\n",
        "        state, reward, done, _ = env.step(action)\n",
        "        total_reward += reward\n",
        "\n",
        "    return total_reward, actions\n",
        "\n",
        "# Function to plot evaluation results\n",
        "def plot_evaluation_results(stock_data, actions):\n",
        "    \"\"\"Plots stock data and overlays model evaluation results.\"\"\"\n",
        "    close_prices = stock_data[:, 3]  # Close prices\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(close_prices, label=\"Close Price\", color='black')\n",
        "\n",
        "    buy_signals = [i for i in range(len(actions)) if actions[i] == 1]\n",
        "    sell_signals = [i for i in range(len(actions)) if actions[i] == 2]\n",
        "\n",
        "    plt.scatter(buy_signals, close_prices[buy_signals], color='green', marker='^', label='Buy')\n",
        "    plt.scatter(sell_signals, close_prices[sell_signals], color='red', marker='v', label='Sell')\n",
        "\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel(\"Stock Price\")\n",
        "    plt.legend()\n",
        "    plt.title(f\"Model Evaluation Results\")\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 283,
      "metadata": {},
      "outputs": [],
      "source": [
        "def init_or_load(input_dim: int = 7,\n",
        "                     output_dim: int = 3,\n",
        "                     lr: float = 1e-3,\n",
        "                     memory_size: int = 10_000):\n",
        "    \"\"\"\n",
        "    Returns (model, optimizer, memory), loading pretrained weights if available.\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Using device:\", device)\n",
        "\n",
        "    model = StockLSTM(input_dim=input_dim, output_dim=output_dim).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    memory = collections.deque(maxlen=memory_size)\n",
        "\n",
        "    if os.path.exists(MODEL_SAVE_PATH):\n",
        "        model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
        "        print(f\" Loaded existing model from {MODEL_SAVE_PATH}\")\n",
        "    else:\n",
        "        print(\"  No existing model found — initialized new network.\")\n",
        "\n",
        "    return model, optimizer, memory, device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 284,
      "metadata": {
        "id": "UsVD4Tjim_Bp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing ticker: MMM\n",
            "Processing ticker: AOS\n",
            "Processing ticker: ABT\n",
            "Processing ticker: ABBV\n",
            "Processing ticker: ACN\n",
            "Processing ticker: ADBE\n",
            "Processing ticker: AMD\n",
            "Processing ticker: AES\n",
            "Processing ticker: AFL\n",
            "Processing ticker: A\n",
            "Processing ticker: APD\n",
            "Processing ticker: ABNB\n",
            "Processing ticker: AKAM\n",
            "Processing ticker: ALB\n",
            "Processing ticker: ARE\n",
            "Processing ticker: ALGN\n",
            "Processing ticker: ALLE\n",
            "Processing ticker: LNT\n",
            "Processing ticker: ALL\n",
            "Processing ticker: GOOGL\n",
            "Processing ticker: GOOG\n",
            "Processing ticker: MO\n",
            "Processing ticker: AMZN\n",
            "Processing ticker: AMCR\n",
            "Processing ticker: AEE\n",
            "Processing ticker: AEP\n",
            "Processing ticker: AXP\n",
            "Processing ticker: AIG\n",
            "Processing ticker: AMT\n",
            "Processing ticker: AWK\n",
            "Processing ticker: AMP\n",
            "Processing ticker: AME\n",
            "Processing ticker: AMGN\n",
            "Processing ticker: APH\n",
            "Processing ticker: ADI\n",
            "Processing ticker: ANSS\n",
            "Processing ticker: AON\n",
            "Processing ticker: APA\n",
            "Processing ticker: APO\n",
            "Processing ticker: AAPL\n",
            "Processing ticker: AMAT\n",
            "Processing ticker: APTV\n",
            "Processing ticker: ACGL\n",
            "Processing ticker: ADM\n",
            "Processing ticker: ANET\n",
            "Processing ticker: AJG\n",
            "Processing ticker: AIZ\n",
            "Processing ticker: T\n",
            "Processing ticker: ATO\n",
            "Processing ticker: ADSK\n",
            "Processing ticker: ADP\n",
            "Processing ticker: AZO\n",
            "Processing ticker: AVB\n",
            "Processing ticker: AVY\n",
            "Processing ticker: AXON\n",
            "Processing ticker: BKR\n",
            "Processing ticker: BALL\n",
            "Processing ticker: BAC\n",
            "Processing ticker: BAX\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "1 Failed download:\n",
            "['BRK.B']: YFTzMissingError('possibly delisted; no timezone found')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing ticker: BDX\n",
            "Warning: Empty data for ticker: BRK.B\n",
            "Processing ticker: BBY\n",
            "Processing ticker: TECH\n",
            "Processing ticker: BIIB\n",
            "Processing ticker: BLK\n",
            "Processing ticker: BX\n",
            "Processing ticker: BK\n",
            "Processing ticker: BA\n",
            "Processing ticker: BKNG\n",
            "Processing ticker: BSX\n",
            "Processing ticker: BMY\n",
            "Processing ticker: AVGO\n",
            "Processing ticker: BR\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "1 Failed download:\n",
            "['BF.B']: YFPricesMissingError('possibly delisted; no price data found  (1d 1926-05-04 -> 2025-04-09)')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing ticker: BRO\n",
            "Warning: Empty data for ticker: BF.B\n",
            "Processing ticker: BLDR\n",
            "Processing ticker: BG\n",
            "Processing ticker: BXP\n",
            "Processing ticker: CHRW\n",
            "Processing ticker: CDNS\n",
            "Processing ticker: CZR\n",
            "Processing ticker: CPT\n",
            "Processing ticker: CPB\n",
            "Processing ticker: COF\n",
            "Processing ticker: CAH\n",
            "Processing ticker: KMX\n",
            "Processing ticker: CCL\n",
            "Processing ticker: CARR\n",
            "Processing ticker: CAT\n",
            "Processing ticker: CBOE\n",
            "Processing ticker: CBRE\n",
            "Processing ticker: CDW\n",
            "Processing ticker: COR\n",
            "Processing ticker: CNC\n",
            "Processing ticker: CNP\n",
            "Processing ticker: CF\n",
            "Processing ticker: CRL\n",
            "Processing ticker: SCHW\n",
            "Processing ticker: CHTR\n",
            "Processing ticker: CVX\n",
            "Processing ticker: CMG\n",
            "Processing ticker: CB\n",
            "Processing ticker: CHD\n",
            "Processing ticker: CI\n",
            "Processing ticker: CINF\n",
            "Processing ticker: CTAS\n",
            "Processing ticker: CSCO\n",
            "Processing ticker: C\n",
            "Processing ticker: CFG\n",
            "Processing ticker: CLX\n",
            "Processing ticker: CME\n",
            "Processing ticker: CMS\n",
            "Processing ticker: KO\n",
            "Processing ticker: CTSH\n",
            "Processing ticker: CL\n",
            "Processing ticker: CMCSA\n",
            "Processing ticker: CAG\n",
            "Processing ticker: COP\n",
            "Processing ticker: ED\n",
            "Processing ticker: STZ\n",
            "Processing ticker: CEG\n",
            "Processing ticker: COO\n",
            "Processing ticker: CPRT\n",
            "Processing ticker: GLW\n",
            "Processing ticker: CPAY\n",
            "Processing ticker: CTVA\n",
            "Processing ticker: CSGP\n",
            "Processing ticker: COST\n",
            "Processing ticker: CTRA\n",
            "Processing ticker: CRWD\n",
            "Processing ticker: CCI\n",
            "Processing ticker: CSX\n",
            "Processing ticker: CMI\n",
            "Processing ticker: CVS\n",
            "Processing ticker: DHR\n",
            "Processing ticker: DRI\n",
            "Processing ticker: DVA\n",
            "Processing ticker: DAY\n",
            "Processing ticker: DECK\n",
            "Processing ticker: DE\n",
            "Processing ticker: DELL\n",
            "Processing ticker: DAL\n",
            "Processing ticker: DVN\n",
            "Processing ticker: DXCM\n",
            "Processing ticker: FANG\n",
            "Processing ticker: DLR\n",
            "Processing ticker: DFS\n",
            "Processing ticker: DG\n",
            "Processing ticker: DLTR\n",
            "Processing ticker: D\n",
            "Processing ticker: DPZ\n",
            "Processing ticker: DASH\n",
            "Processing ticker: DOV\n",
            "Processing ticker: DOW\n",
            "Processing ticker: DHI\n",
            "Processing ticker: DTE\n",
            "Processing ticker: DUK\n",
            "Processing ticker: DD\n",
            "Processing ticker: EMN\n",
            "Processing ticker: ETN\n",
            "Processing ticker: EBAY\n",
            "Processing ticker: ECL\n",
            "Processing ticker: EIX\n",
            "Processing ticker: EW\n",
            "Processing ticker: EA\n",
            "Processing ticker: ELV\n",
            "Processing ticker: EMR\n",
            "Processing ticker: ENPH\n",
            "Processing ticker: ETR\n",
            "Processing ticker: EOG\n",
            "Processing ticker: EPAM\n",
            "Processing ticker: EQT\n",
            "Processing ticker: EFX\n",
            "Processing ticker: EQIX\n",
            "Processing ticker: EQR\n",
            "Processing ticker: ERIE\n",
            "Processing ticker: ESS\n",
            "Processing ticker: EL\n",
            "Processing ticker: EG\n",
            "Processing ticker: EVRG\n",
            "Processing ticker: ES\n",
            "Processing ticker: EXC\n",
            "Processing ticker: EXE\n",
            "Processing ticker: EXPE\n",
            "Processing ticker: EXPD\n",
            "Processing ticker: EXR\n",
            "Processing ticker: XOM\n",
            "Processing ticker: FFIV\n",
            "Processing ticker: FDS\n",
            "Processing ticker: FICO\n",
            "Processing ticker: FAST\n",
            "Processing ticker: FRT\n",
            "Processing ticker: FDX\n",
            "Processing ticker: FIS\n",
            "Processing ticker: FITB\n",
            "Processing ticker: FSLR\n",
            "Processing ticker: FE\n",
            "Processing ticker: FI\n",
            "Processing ticker: F\n",
            "Processing ticker: FTNT\n",
            "Processing ticker: FTV\n",
            "Processing ticker: FOXA\n",
            "Processing ticker: FOX\n",
            "Processing ticker: BEN\n",
            "Processing ticker: FCX\n",
            "Processing ticker: GRMN\n",
            "Processing ticker: IT\n",
            "Processing ticker: GE\n",
            "Processing ticker: GEHC\n",
            "Processing ticker: GEV\n",
            "Processing ticker: GEN\n",
            "Processing ticker: GNRC\n",
            "Processing ticker: GD\n",
            "Processing ticker: GIS\n",
            "Processing ticker: GM\n",
            "Processing ticker: GPC\n",
            "Processing ticker: GILD\n",
            "Processing ticker: GPN\n",
            "Processing ticker: GL\n",
            "Processing ticker: GDDY\n",
            "Processing ticker: GS\n",
            "Processing ticker: HAL\n",
            "Processing ticker: HIG\n",
            "Processing ticker: HAS\n",
            "Processing ticker: HCA\n",
            "Processing ticker: DOC\n",
            "Processing ticker: HSIC\n",
            "Processing ticker: HSY\n",
            "Processing ticker: HES\n",
            "Processing ticker: HPE\n",
            "Processing ticker: HLT\n",
            "Processing ticker: HOLX\n",
            "Processing ticker: HD\n",
            "Processing ticker: HON\n",
            "Processing ticker: HRL\n",
            "Processing ticker: HST\n",
            "Processing ticker: HWM\n",
            "Processing ticker: HPQ\n",
            "Processing ticker: HUBB\n",
            "Processing ticker: HUM\n",
            "Processing ticker: HBAN\n",
            "Processing ticker: HII\n",
            "Processing ticker: IBM\n",
            "Processing ticker: IEX\n",
            "Processing ticker: IDXX\n",
            "Processing ticker: ITW\n",
            "Processing ticker: INCY\n",
            "Processing ticker: IR\n",
            "Processing ticker: PODD\n",
            "Processing ticker: INTC\n",
            "Processing ticker: ICE\n",
            "Processing ticker: IFF\n",
            "Processing ticker: IP\n",
            "Processing ticker: IPG\n",
            "Processing ticker: INTU\n",
            "Processing ticker: ISRG\n",
            "Processing ticker: IVZ\n",
            "Processing ticker: INVH\n",
            "Processing ticker: IQV\n",
            "Processing ticker: IRM\n",
            "Processing ticker: JBHT\n",
            "Processing ticker: JBL\n",
            "Processing ticker: JKHY\n",
            "Processing ticker: J\n",
            "Processing ticker: JNJ\n",
            "Processing ticker: JCI\n",
            "Processing ticker: JPM\n",
            "Processing ticker: JNPR\n",
            "Processing ticker: K\n",
            "Processing ticker: KVUE\n",
            "Processing ticker: KDP\n",
            "Processing ticker: KEY\n",
            "Processing ticker: KEYS\n",
            "Processing ticker: KMB\n",
            "Processing ticker: KIM\n",
            "Processing ticker: KMI\n",
            "Processing ticker: KKR\n",
            "Processing ticker: KLAC\n",
            "Processing ticker: KHC\n",
            "Processing ticker: KR\n",
            "Processing ticker: LHX\n",
            "Processing ticker: LH\n",
            "Processing ticker: LRCX\n",
            "Processing ticker: LW\n",
            "Processing ticker: LVS\n",
            "Processing ticker: LDOS\n",
            "Processing ticker: LEN\n",
            "Processing ticker: LII\n",
            "Processing ticker: LLY\n",
            "Processing ticker: LIN\n",
            "Processing ticker: LYV\n",
            "Processing ticker: LKQ\n",
            "Processing ticker: LMT\n",
            "Processing ticker: L\n",
            "Processing ticker: LOW\n",
            "Processing ticker: LULU\n",
            "Processing ticker: LYB\n",
            "Processing ticker: MTB\n",
            "Processing ticker: MPC\n",
            "Processing ticker: MKTX\n",
            "Processing ticker: MAR\n",
            "Processing ticker: MMC\n",
            "Processing ticker: MLM\n",
            "Processing ticker: MAS\n",
            "Processing ticker: MA\n",
            "Processing ticker: MTCH\n",
            "Processing ticker: MKC\n",
            "Processing ticker: MCD\n",
            "Processing ticker: MCK\n",
            "Processing ticker: MDT\n",
            "Processing ticker: MRK\n",
            "Processing ticker: META\n",
            "Processing ticker: MET\n",
            "Processing ticker: MTD\n",
            "Processing ticker: MGM\n",
            "Processing ticker: MCHP\n",
            "Processing ticker: MU\n",
            "Processing ticker: MSFT\n",
            "Processing ticker: MAA\n",
            "Processing ticker: MRNA\n",
            "Processing ticker: MHK\n",
            "Processing ticker: MOH\n",
            "Processing ticker: TAP\n",
            "Processing ticker: MDLZ\n",
            "Processing ticker: MPWR\n",
            "Processing ticker: MNST\n",
            "Processing ticker: MCO\n",
            "Processing ticker: MS\n",
            "Processing ticker: MOS\n",
            "Processing ticker: MSI\n",
            "Processing ticker: MSCI\n",
            "Processing ticker: NDAQ\n",
            "Processing ticker: NTAP\n",
            "Processing ticker: NFLX\n",
            "Processing ticker: NEM\n",
            "Processing ticker: NWSA\n",
            "Processing ticker: NWS\n",
            "Processing ticker: NEE\n",
            "Processing ticker: NKE\n",
            "Processing ticker: NI\n",
            "Processing ticker: NDSN\n",
            "Processing ticker: NSC\n",
            "Processing ticker: NTRS\n",
            "Processing ticker: NOC\n",
            "Processing ticker: NCLH\n",
            "Processing ticker: NRG\n",
            "Processing ticker: NUE\n",
            "Processing ticker: NVDA\n",
            "Processing ticker: NVR\n",
            "Processing ticker: NXPI\n",
            "Processing ticker: ORLY\n",
            "Processing ticker: OXY\n",
            "Processing ticker: ODFL\n",
            "Processing ticker: OMC\n",
            "Processing ticker: ON\n",
            "Processing ticker: OKE\n",
            "Processing ticker: ORCL\n",
            "Processing ticker: OTIS\n",
            "Processing ticker: PCAR\n",
            "Processing ticker: PKG\n",
            "Processing ticker: PLTR\n",
            "Processing ticker: PANW\n",
            "Processing ticker: PARA\n",
            "Processing ticker: PH\n",
            "Processing ticker: PAYX\n",
            "Processing ticker: PAYC\n",
            "Processing ticker: PYPL\n",
            "Processing ticker: PNR\n",
            "Processing ticker: PEP\n",
            "Processing ticker: PFE\n",
            "Processing ticker: PCG\n",
            "Processing ticker: PM\n",
            "Processing ticker: PSX\n",
            "Processing ticker: PNW\n",
            "Processing ticker: PNC\n",
            "Processing ticker: POOL\n",
            "Processing ticker: PPG\n",
            "Processing ticker: PPL\n",
            "Processing ticker: PFG\n",
            "Processing ticker: PG\n",
            "Processing ticker: PGR\n",
            "Processing ticker: PLD\n",
            "Processing ticker: PRU\n",
            "Processing ticker: PEG\n",
            "Processing ticker: PTC\n",
            "Processing ticker: PSA\n",
            "Processing ticker: PHM\n",
            "Processing ticker: PWR\n",
            "Processing ticker: QCOM\n",
            "Processing ticker: DGX\n",
            "Processing ticker: RL\n",
            "Processing ticker: RJF\n",
            "Processing ticker: RTX\n",
            "Processing ticker: O\n",
            "Processing ticker: REG\n",
            "Processing ticker: REGN\n",
            "Processing ticker: RF\n",
            "Processing ticker: RSG\n",
            "Processing ticker: RMD\n",
            "Processing ticker: RVTY\n",
            "Processing ticker: ROK\n",
            "Processing ticker: ROL\n",
            "Processing ticker: ROP\n",
            "Processing ticker: ROST\n",
            "Processing ticker: RCL\n",
            "Processing ticker: SPGI\n",
            "Processing ticker: CRM\n",
            "Processing ticker: SBAC\n",
            "Processing ticker: SLB\n",
            "Processing ticker: STX\n",
            "Processing ticker: SRE\n",
            "Processing ticker: NOW\n",
            "Processing ticker: SHW\n",
            "Processing ticker: SPG\n",
            "Processing ticker: SWKS\n",
            "Processing ticker: SJM\n",
            "Processing ticker: SW\n",
            "Processing ticker: SNA\n",
            "Processing ticker: SOLV\n",
            "Processing ticker: SO\n",
            "Processing ticker: LUV\n",
            "Processing ticker: SWK\n",
            "Processing ticker: SBUX\n",
            "Processing ticker: STT\n",
            "Processing ticker: STLD\n",
            "Processing ticker: STE\n",
            "Processing ticker: SYK\n",
            "Processing ticker: SMCI\n",
            "Processing ticker: SYF\n",
            "Processing ticker: SNPS\n",
            "Processing ticker: SYY\n",
            "Processing ticker: TMUS\n",
            "Processing ticker: TROW\n",
            "Processing ticker: TTWO\n",
            "Processing ticker: TPR\n",
            "Processing ticker: TRGP\n",
            "Processing ticker: TGT\n",
            "Processing ticker: TEL\n",
            "Processing ticker: TDY\n",
            "Processing ticker: TER\n",
            "Processing ticker: TSLA\n",
            "Processing ticker: TXN\n",
            "Processing ticker: TPL\n",
            "Processing ticker: TXT\n",
            "Processing ticker: TMO\n",
            "Processing ticker: TJX\n",
            "Processing ticker: TKO\n",
            "Processing ticker: TSCO\n",
            "Processing ticker: TT\n",
            "Processing ticker: TDG\n",
            "Processing ticker: TRV\n",
            "Processing ticker: TRMB\n",
            "Processing ticker: TFC\n",
            "Processing ticker: TYL\n",
            "Processing ticker: TSN\n",
            "Processing ticker: USB\n",
            "Processing ticker: UBER\n",
            "Processing ticker: UDR\n",
            "Processing ticker: ULTA\n",
            "Processing ticker: UNP\n",
            "Processing ticker: UAL\n",
            "Processing ticker: UPS\n",
            "Processing ticker: URI\n",
            "Processing ticker: UNH\n",
            "Processing ticker: UHS\n",
            "Processing ticker: VLO\n",
            "Processing ticker: VTR\n",
            "Processing ticker: VLTO\n",
            "Processing ticker: VRSN\n",
            "Processing ticker: VRSK\n",
            "Processing ticker: VZ\n",
            "Processing ticker: VRTX\n",
            "Processing ticker: VTRS\n",
            "Processing ticker: VICI\n",
            "Processing ticker: V\n",
            "Processing ticker: VST\n",
            "Processing ticker: VMC\n",
            "Processing ticker: WRB\n",
            "Processing ticker: GWW\n",
            "Processing ticker: WAB\n",
            "Processing ticker: WBA\n",
            "Processing ticker: WMT\n",
            "Processing ticker: DIS\n",
            "Processing ticker: WBD\n",
            "Processing ticker: WM\n",
            "Processing ticker: WAT\n",
            "Processing ticker: WEC\n",
            "Processing ticker: WFC\n",
            "Processing ticker: WELL\n",
            "Processing ticker: WST\n",
            "Processing ticker: WDC\n",
            "Processing ticker: WY\n",
            "Processing ticker: WSM\n",
            "Processing ticker: WMB\n",
            "Processing ticker: WTW\n",
            "Processing ticker: WDAY\n",
            "Processing ticker: WYNN\n",
            "Processing ticker: XEL\n",
            "Processing ticker: XYL\n",
            "Processing ticker: YUM\n",
            "Processing ticker: ZBRA\n",
            "Processing ticker: ZBH\n",
            "Processing ticker: ZTS\n",
            "Scaler saved\n",
            "Saved Dataset.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if os.path.exists(\"data/stock_dataset.pkl\"):\n",
        "    dataset = StockDataset.load(\"data/stock_dataset.pkl\")\n",
        "else:\n",
        "    tickers = pd.read_html(SP500_TICKERS)[0]['Symbol'].tolist()\n",
        "    dataset = StockDataset(tickers, num_segments=10)\n",
        "    dataset.save(\"data/stock_dataset.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class StockLSTM(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=128, lstm_layers=1, fc_dim=64, output_dim=3):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.lstm_layers = lstm_layers\n",
        "\n",
        "        dropout = 0.2 if lstm_layers > 1 else 0.0\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=lstm_layers, batch_first=True, dropout=dropout)\n",
        "\n",
        "        self.layer_norm = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "        # Actor head\n",
        "        self.actor_fc1 = nn.Linear(hidden_dim, fc_dim)\n",
        "        self.actor_fc2 = nn.Linear(fc_dim, output_dim)  # logits for actions\n",
        "\n",
        "        # Critic head\n",
        "        self.critic_fc1 = nn.Linear(hidden_dim, fc_dim)\n",
        "        self.critic_fc2 = nn.Linear(fc_dim, 1)  # state-value\n",
        "\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x, hidden_state=None):\n",
        "        # x: (batch_size, seq_len, input_dim)\n",
        "        if hidden_state is None:\n",
        "            h0 = torch.zeros(self.lstm_layers, x.size(0), self.hidden_dim).to(x.device)\n",
        "            c0 = torch.zeros(self.lstm_layers, x.size(0), self.hidden_dim).to(x.device)\n",
        "            hidden_state = (h0, c0)\n",
        "\n",
        "        lstm_out, new_hidden = self.lstm(x, hidden_state)\n",
        "        last_output = lstm_out[:, -1, :]  # use last output\n",
        "        normed = self.layer_norm(last_output)\n",
        "        dropped = self.dropout(normed)\n",
        "\n",
        "        # Actor\n",
        "        actor_hidden = F.relu(self.actor_fc1(dropped))\n",
        "        policy_logits = self.actor_fc2(actor_hidden)\n",
        "\n",
        "        # Critic\n",
        "        critic_hidden = F.relu(self.critic_fc1(dropped))\n",
        "        value = self.critic_fc2(critic_hidden)\n",
        "\n",
        "        return policy_logits, value, new_hidden\n",
        "\n",
        "\n",
        "\n",
        "# Train the RL agent using StockDataset\n",
        "def train_on_sp500(dataset, episodes=10, batch_size=64, gamma=0.95, lr=0.001, save_interval=30):\n",
        "    model, optimizer, _, device = init_or_load(input_dim=7, output_dim=3, lr=lr)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    if os.path.exists(MODEL_SAVE_PATH):\n",
        "        model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
        "        print(\"Loaded existing model.\")\n",
        "\n",
        "    window_size = 30\n",
        "\n",
        "    while True:\n",
        "        stock_data, ticker = dataset.fetch_next_stock()\n",
        "        if stock_data is None:\n",
        "            print(\"All data segments processed, restarting training loop...\")\n",
        "            break\n",
        "\n",
        "        if isinstance(stock_data, np.ndarray):\n",
        "            stock_data = pd.DataFrame(stock_data)\n",
        "\n",
        "        if len(stock_data) < window_size:\n",
        "            print(f\"Skipping stock {ticker}: only {len(stock_data)} rows (<{window_size}).\")\n",
        "            continue\n",
        "\n",
        "        env = TradingEnv(stock_data, window_size=window_size)\n",
        "\n",
        "        wins = 0\n",
        "        action_counter = collections.Counter()\n",
        "\n",
        "        for episode in range(episodes):\n",
        "            state = env.reset()\n",
        "            action_counter.clear()\n",
        "            done = False\n",
        "            total_reward = 0\n",
        "            PROFIT = 0\n",
        "            tax_credit = 0\n",
        "\n",
        "            episode_states = []\n",
        "            episode_actions = []\n",
        "            episode_rewards = []\n",
        "\n",
        "            while not done:\n",
        "                state_tensor = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0) #!\n",
        "                logits, value, _ = model(state_tensor)\n",
        "                dist = Categorical(logits=logits)\n",
        "                action = dist.sample().item()\n",
        "\n",
        "                next_state, reward, done, _ = env.step(action)\n",
        "\n",
        "                episode_states.append(state)\n",
        "                episode_actions.append(action)\n",
        "                episode_rewards.append(reward)\n",
        "\n",
        "                state = next_state\n",
        "                action_counter[action] += 1\n",
        "\n",
        "            # Compute returns\n",
        "            returns = []\n",
        "            G = 0\n",
        "            for r in reversed(episode_rewards):\n",
        "                G = r + gamma * G\n",
        "                returns.insert(0, G)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            for state, action, G in zip(episode_states, episode_actions, returns):\n",
        "                state_tensor = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
        "                logits, value, _ = model(state_tensor)\n",
        "                dist = Categorical(logits=logits)\n",
        "\n",
        "                action_tensor = torch.tensor(action, device=device)\n",
        "                log_prob = dist.log_prob(action_tensor)\n",
        "                advantage = G - value.squeeze().detach()\n",
        "\n",
        "                policy_loss = -log_prob * advantage\n",
        "                value_loss = F.mse_loss(value.squeeze(), torch.tensor(G, device=device))\n",
        "                (policy_loss + value_loss).backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            net_profit = env.net_worth - env.initial_balance\n",
        "\n",
        "            if net_profit > 0:\n",
        "                wins += 1\n",
        "                tax_liability = 0.25 * net_profit\n",
        "                tax_due = max(tax_liability - tax_credit, 0)\n",
        "                tax_credit = max(tax_credit - tax_liability, 0)\n",
        "            else:\n",
        "                tax_due = 0\n",
        "                tax_credit += abs(net_profit) * 0.25\n",
        "\n",
        "            net_profit_after_tax = net_profit - tax_due\n",
        "            PROFIT += net_profit_after_tax\n",
        "\n",
        "            print(f\"Ticker: {ticker} | Episode {episode+1}/{episodes} | Net PnL: {net_profit:.2f} | Wins: {wins}/{episode+1}\")\n",
        "\n",
        "            if episode % save_interval == 0:\n",
        "                torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "                print(\"Model progress saved.\")\n",
        "\n",
        "        total_reward, actions = evaluate_model(stock_data, model)\n",
        "        plot_evaluation_results(stock_data, actions)\n",
        "\n",
        "    print(\"Training complete.\")\n",
        "    torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "    print(\"Final model saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 286,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VPPJh-7am_Bq",
        "outputId": "df191946-a1db-4c90-d1c9-5fa4f799087c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "  No existing model found — initialized new network.\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "expected sequence of length 30 at dim 0 (got 7)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[286], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run training\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain_on_sp500\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[285], line 88\u001b[0m, in \u001b[0;36mtrain_on_sp500\u001b[1;34m(dataset, episodes, batch_size, gamma, lr, save_interval)\u001b[0m\n\u001b[0;32m     85\u001b[0m episode_rewards \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[1;32m---> 88\u001b[0m     state_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     89\u001b[0m     logits, value, _ \u001b[38;5;241m=\u001b[39m model(state_tensor)\n\u001b[0;32m     90\u001b[0m     dist \u001b[38;5;241m=\u001b[39m Categorical(logits\u001b[38;5;241m=\u001b[39mlogits)\n",
            "\u001b[1;31mValueError\u001b[0m: expected sequence of length 30 at dim 0 (got 7)"
          ]
        }
      ],
      "source": [
        "\n",
        "# Run training\n",
        "train_on_sp500(dataset, episodes=10)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
