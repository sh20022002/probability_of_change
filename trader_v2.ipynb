{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sh20022002/probability_of_change/blob/main/trader_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {
        "id": "QXajTKy6m_Bl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pickle\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from torchrl.envs import EnvBase\n",
        "from tensordict import TensorDict\n",
        "from torchrl.envs.utils import step_mdp\n",
        "from torch.distributions import Categorical\n",
        "from tensordict import TensorDict\n",
        "from torchrl.collectors import SyncDataCollector\n",
        "from torchrl.data import ReplayBuffer, LazyTensorStorage\n",
        "from torchrl.objectives import A2CLoss, ValueEstimators\n",
        "from tensordict import TensorDictBase\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from torchrl.data import Unbounded, OneHot\n",
        "from torchrl.modules.distributions.continuous import TanhNormal\n",
        "from torchrl.modules import Actor\n",
        "from tensordict.nn import TensorDictModule\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import  Dataset\n",
        "import torch.optim as optim\n",
        "\n",
        "import collections\n",
        "import warnings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "MODEL_SAVE_PATH = \"trading_model.pth\"\n",
        "SP500_TICKERS = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
        "COLUMNS = ['Open', 'Close', 'Volume', 'MACD', 'ATR'] #change to open close volume macd rsi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_macd(df: pd.DataFrame, fast_period: int = 12, slow_period: int = 26, signal_period: int = 9) -> pd.DataFrame:\n",
        "    \"\"\"Calculate MACD, Signal Line, and MACD Histogram.\"\"\"\n",
        "    df = df.copy()\n",
        "    df['EMA_fast'] = df['Close'].ewm(span=fast_period, adjust=False).mean()\n",
        "    df['EMA_slow'] = df['Close'].ewm(span=slow_period, adjust=False).mean()\n",
        "    df['MACD'] = df['EMA_fast'] - df['EMA_slow']\n",
        "    return df['MACD']\n",
        "\n",
        "def calculate_atr(df: pd.DataFrame, period: int = 14) -> pd.Series:\n",
        "    \"\"\"Calculate Average True Range (ATR).\"\"\"\n",
        "    df = df.copy()\n",
        "    df['H-L'] = df['High'] - df['Low']\n",
        "    df['H-PC'] = np.abs(df['High'] - df['Close'].shift(1))\n",
        "    df['L-PC'] = np.abs(df['Low'] - df['Close'].shift(1))\n",
        "    df['TR'] = df[['H-L', 'H-PC', 'L-PC']].max(axis=1)\n",
        "    atr = df['TR'].ewm(span=period, adjust=False).mean()\n",
        "    return atr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class StockDataset(Dataset):\n",
        "    def __init__(self, tickers):\n",
        "        self.tickers = tickers\n",
        "        self.segmented_data = []\n",
        "        self.current_ticker_idx = 0\n",
        "\n",
        "        self._load_and_split_data()\n",
        "\n",
        "    def _load_and_split_data(self):\n",
        "        saved = False\n",
        "        for ticker in self.tickers:\n",
        "            print(f\"Processing ticker: {ticker}\")\n",
        "\n",
        "            try:\n",
        "                df = yf.download(ticker, period='max', progress=False)\n",
        "                if df.empty:\n",
        "                    print(f\"Warning: Empty data for ticker: {ticker}\")\n",
        "                    continue\n",
        "                \n",
        "                df = df.dropna()\n",
        "                \n",
        "                df['MACD'] = calculate_macd(df)\n",
        "                df['ATR'] = calculate_atr(df)\n",
        "\n",
        "                features = df[COLUMNS].dropna()\n",
        "                if features.empty:\n",
        "                    continue\n",
        "\n",
        "                    \n",
        "                # Select features to scale\n",
        "                scaler = StandardScaler()\n",
        "                scaled_data = scaler.fit_transform(features)\n",
        "\n",
        "                # Save the fitted scaler\n",
        "                if not saved:\n",
        "                    os.makedirs(\"data\", exist_ok=True)\n",
        "                    with open(\"data/scaler.pkl\", \"wb\") as f:\n",
        "                        pickle.dump(scaler, f)\n",
        "                        saved = True\n",
        "                        \n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error downloading data for {ticker}: {e}\")\n",
        "                continue        \n",
        "\n",
        "            scaled_values = scaled_data.astype(np.float32)\n",
        "            self.segmented_data.append((scaled_values, ticker))\n",
        "            self.current_ticker_idx += 1\n",
        "\n",
        "            \n",
        "    def __len__(self):\n",
        "        return len(self.segmented_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.segmented_data[idx]\n",
        "\n",
        "\n",
        "    def fetch_next_stock(self):\n",
        "        \"\"\"Returns a dataset segment in order, keeping track of stock index.\"\"\"\n",
        "        if not self.segmented_data:\n",
        "            return None, None  # No more stocks\n",
        "\n",
        "        if self.current_ticker_idx >= len(self.segmented_data):\n",
        "            self.current_ticker_idx = 0  # Loop back to start\n",
        "\n",
        "        segment, ticker = self.segmented_data[self.current_ticker_idx]\n",
        "        self.current_ticker_idx += 1\n",
        "        return segment, ticker\n",
        "\n",
        "    def save(self, path):\n",
        "        \"\"\"\n",
        "        Saves the StockDataset to a pickle file.\n",
        "\n",
        "        Args:\n",
        "            filepath (str): The path to the pickle file.\n",
        "        \"\"\"\n",
        "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "        with open(path, 'wb') as f:\n",
        "            pickle.dump(self, f)\n",
        "        print('Saved Dataset.')\n",
        "\n",
        "    @staticmethod\n",
        "    def load(path):\n",
        "        \"\"\"\n",
        "        Loads the StockDataset from a pickle file.\n",
        "\n",
        "        Args:\n",
        "            filepath (str): The path to the pickle file.\n",
        "\n",
        "        Returns:\n",
        "            StockDataset: The loaded StockDataset object.\n",
        "        \"\"\"\n",
        "        with open(path, 'rb') as f:\n",
        "            return pickle.load(f)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TradingEnv(EnvBase):\n",
        "    def __init__(self, df: pd.DataFrame, window_size=30):\n",
        "        super().__init__()\n",
        "\n",
        "        if isinstance(df, np.ndarray):\n",
        "            df = pd.DataFrame(df)\n",
        "\n",
        "        if len(df) < window_size:\n",
        "            raise ValueError(f\"Insufficient data: need at least {window_size} rows, got {len(df)}.\")\n",
        "\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.initial_balance = 1000.0\n",
        "        self.balance = 1000.0\n",
        "        self.net_worth = 1000.0\n",
        "        self.window_size = window_size\n",
        "        self.current_step = 0\n",
        "\n",
        "        obs_dim = window_size * self.df.shape[1]\n",
        "        self.observation_spec = Unbounded(shape=(obs_dim,))\n",
        "        self.action_spec = OneHot(n=4)\n",
        "        self._set_seed(0)\n",
        "\n",
        "    def _reset(self, tensordict=None):\n",
        "        self.current_step = self.window_size\n",
        "        self.balance = self.initial_balance\n",
        "        self.net_worth = self.initial_balance\n",
        "        self.positions = []\n",
        "        self.position_type = None\n",
        "        self.trades = []\n",
        "\n",
        "        obs = self._get_observation()\n",
        "        return TensorDict({\"observation\": obs.unsqueeze(0)}, batch_size=[])\n",
        "\n",
        "    def _get_observation(self):\n",
        "        frame = self.df.iloc[self.current_step - self.window_size:self.current_step].copy()\n",
        "        frame[\"Balance\"] = self.balance\n",
        "        frame[\"NetWorth\"] = self.net_worth\n",
        "\n",
        "        obs = torch.tensor(frame.astype(np.float32).values, dtype=torch.float32)\n",
        "        return obs\n",
        "\n",
        "    def _set_seed(self, seed: int):\n",
        "        torch.manual_seed(seed)\n",
        "        np.random.seed(seed)\n",
        "        random.seed(seed)\n",
        "        return seed\n",
        "\n",
        "    def _step(self, tensordict):\n",
        "        action = tensordict[\"action\"].item()\n",
        "        reward = 0.0\n",
        "        done = False\n",
        "\n",
        "        current_price = self.df.iloc[self.current_step]['Close']\n",
        "\n",
        "        if action == 0:  # Buy\n",
        "            if self.position_type is None:\n",
        "                self.positions.append(current_price)\n",
        "                self.position_type = 'long'\n",
        "            elif self.position_type == 'short':\n",
        "                entry = self.positions.pop(0)\n",
        "                profit = entry - current_price\n",
        "                reward += profit\n",
        "                self.balance += profit\n",
        "                if not self.positions:\n",
        "                    self.position_type = None\n",
        "\n",
        "        elif action == 1:  # Sell\n",
        "            if self.position_type == 'long':\n",
        "                entry = self.positions.pop(0)\n",
        "                profit = current_price - entry\n",
        "                reward += profit\n",
        "                self.balance += profit\n",
        "                if not self.positions:\n",
        "                    self.position_type = None\n",
        "\n",
        "        elif action == 2:  # Short\n",
        "            if self.position_type is None:\n",
        "                self.positions.append(current_price)\n",
        "                self.position_type = 'short'\n",
        "            elif self.position_type == 'long':\n",
        "                entry = self.positions.pop(0)\n",
        "                profit = current_price - entry\n",
        "                reward += profit\n",
        "                self.balance += profit\n",
        "                if not self.positions:\n",
        "                    self.position_type = None\n",
        "\n",
        "        elif action == 3:  # Cover\n",
        "            if self.position_type == 'short':\n",
        "                entry = self.positions.pop(0)\n",
        "                profit = entry - current_price\n",
        "                reward += profit\n",
        "                self.balance += profit\n",
        "                if not self.positions:\n",
        "                    self.position_type = None\n",
        "\n",
        "        self.net_worth = self.balance\n",
        "        self.trades.append((self.current_step, action, current_price, reward))\n",
        "\n",
        "        self.current_step += 1\n",
        "        if self.current_step >= len(self.df):\n",
        "            done = True\n",
        "\n",
        "        next_obs = self._get_observation()\n",
        "\n",
        "        return TensorDict({\n",
        "            \"next\": TensorDict({\"observation\": next_obs.unsqueeze(0)}, batch_size=[]),\n",
        "            \"reward\": torch.tensor([reward], dtype=torch.float32),\n",
        "            \"done\": torch.tensor([done], dtype=torch.bool),\n",
        "            \"terminated\": torch.tensor([done], dtype=torch.bool),\n",
        "        }, batch_size=[])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model(stock_data, model):\n",
        "    \"\"\"Evaluates the model on stock data and returns total reward.\"\"\"\n",
        "    env = TradingEnv(stock_data)\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "    actions = []\n",
        "\n",
        "    while not done:\n",
        "        with torch.inference_mode:\n",
        "            state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0)\n",
        "            logits, value, _ = model(state_tensor)\n",
        "            action = torch.argmax(logits).item()\n",
        "\n",
        "\n",
        "        actions.append(action)\n",
        "        state, reward, done, _ = env.step(action)\n",
        "        total_reward += reward\n",
        "\n",
        "    return total_reward, actions\n",
        "\n",
        "# Function to plot evaluation results\n",
        "def plot_evaluation_results(stock_data, actions):\n",
        "    \"\"\"Plots stock data and overlays model evaluation results.\"\"\"\n",
        "    close_prices = stock_data[:, 3]  # Close prices\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(close_prices, label=\"Close Price\", color='black')\n",
        "\n",
        "    buy_signals = [i for i in range(len(actions)) if actions[i] == 1]\n",
        "    sell_signals = [i for i in range(len(actions)) if actions[i] == 2]\n",
        "\n",
        "    plt.scatter(buy_signals, close_prices[buy_signals], color='green', marker='^', label='Buy')\n",
        "    plt.scatter(sell_signals, close_prices[sell_signals], color='red', marker='v', label='Sell')\n",
        "\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel(\"Stock Price\")\n",
        "    plt.legend()\n",
        "    plt.title(f\"Model Evaluation Results\")\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {
        "id": "UsVD4Tjim_Bp"
      },
      "outputs": [],
      "source": [
        "\n",
        "if os.path.exists(\"data/stock_dataset.pkl\"):\n",
        "    dataset = StockDataset.load(\"data/stock_dataset.pkl\")\n",
        "else:\n",
        "    tickers = pd.read_html(SP500_TICKERS)[0]['Symbol'].tolist()\n",
        "    dataset = StockDataset(tickers)\n",
        "    dataset.save(\"data/stock_dataset.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(array([[-0.7405194 , -0.7300623 , -0.87796915, -0.07685785, -0.66487986],\n",
            "       [-0.7405194 , -0.72995913, -0.7758922 , -0.07643412, -0.66538656],\n",
            "       [-0.7405194 , -0.72995913, -0.87796915, -0.07610697, -0.6665013 ],\n",
            "       ...,\n",
            "       [ 2.6384516 ,  2.5597277 ,  0.9142302 , -4.8513846 ,  7.275909  ],\n",
            "       [ 2.5477831 ,  2.628197  ,  0.20786287, -4.0690956 ,  6.952138  ],\n",
            "       [ 2.6292393 ,  2.5903203 , -0.10967056, -3.566246  ,  6.235909  ]],\n",
            "      dtype=float32), 'MMM')\n"
          ]
        }
      ],
      "source": [
        "print(dataset.fetch_next_stock())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class StockLSTM(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=128, lstm_layers=2, fc_dim=64, output_dim=4):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.lstm_layers = lstm_layers\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, lstm_layers, batch_first=True, dropout=0.2 if lstm_layers > 1 else 0.0)\n",
        "        self.norm = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "        self.actor = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, fc_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(fc_dim, output_dim)\n",
        "        )\n",
        "\n",
        "        self.critic = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, fc_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(fc_dim, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, tensordict: TensorDictBase) -> torch.Tensor:\n",
        "        obs = tensordict[\"observation\"]\n",
        "        if obs.ndim == 2:\n",
        "            obs = obs.unsqueeze(0)\n",
        "        batch_size, seq_len = obs.size(0), obs.size(1)\n",
        "        lengths = tensordict.get(\n",
        "            \"lengths\", torch.full((batch_size,), seq_len, dtype=torch.long, device=obs.device)\n",
        "        )\n",
        "        packed = pack_padded_sequence(obs, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "        packed_out, _ = self.lstm(packed)\n",
        "        lstm_out, _ = pad_packed_sequence(packed_out, batch_first=True)\n",
        "        idx = (lengths - 1).unsqueeze(1).unsqueeze(2).expand(-1, 1, self.hidden_dim)\n",
        "        last_out = lstm_out.gather(1, idx).squeeze(1)\n",
        "        last_out = self.norm(last_out)\n",
        "        return last_out\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "metadata": {},
      "outputs": [],
      "source": [
        "def init_or_load(input_dim: int = 7,\n",
        "                     output_dim: int = 3,\n",
        "                     lr: float = 1e-3,\n",
        "                     memory_size: int = 10_000):\n",
        "    \"\"\"\n",
        "    Returns (model, optimizer, memory), loading pretrained weights if available.\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Using device:\", device)\n",
        "\n",
        "    model = StockLSTM(input_dim=input_dim, output_dim=output_dim).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    memory = collections.deque(maxlen=memory_size)\n",
        "\n",
        "    if os.path.exists(MODEL_SAVE_PATH):\n",
        "        model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
        "        print(f\" Loaded existing model from {MODEL_SAVE_PATH}\")\n",
        "    else:\n",
        "        print(\"  No existing model found — initialized new network.\")\n",
        "\n",
        "    return model, optimizer, memory, device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def convert_state(state):\n",
        "    if isinstance(state, np.ndarray):\n",
        "        state = torch.tensor(state, dtype=torch.float32)\n",
        "    if isinstance(state, list):\n",
        "        state = torch.tensor(state, dtype=torch.float32)\n",
        "    if state.ndim == 2:\n",
        "        state = state.unsqueeze(0)\n",
        "    return state\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def train(dataset, episodes=30, gamma=0.95, lr=1e-3):\n",
        "    model, optimizer, _, device = init_or_load(input_dim=7, output_dim=4, lr=lr)\n",
        "    model = model.to(device)\n",
        "    \n",
        "\n",
        "    if os.path.exists(MODEL_SAVE_PATH):\n",
        "        model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
        "        print(\"Loaded existing model.\")\n",
        "\n",
        "    window_size = 7\n",
        "\n",
        "    while True:\n",
        "        stock_data, ticker = dataset.fetch_next_stock()\n",
        "        if stock_data is None:\n",
        "            print(\"All data segments processed, restarting training loop...\")\n",
        "            break\n",
        "\n",
        "        if isinstance(stock_data, np.ndarray):\n",
        "            stock_data = pd.DataFrame(stock_data)\n",
        "\n",
        "        if len(stock_data) < window_size:\n",
        "            print(f\"Skipping stock {ticker}: only {len(stock_data)} rows (<{window_size}).\")\n",
        "            continue\n",
        "\n",
        "        env = TradingEnv(stock_data, window_size=window_size)\n",
        "\n",
        "        collector = SyncDataCollector(\n",
        "            create_env_fn=lambda: env,\n",
        "            policy=lambda td: TensorDict({\"action\": Categorical(logits=model(td)).sample()}, batch_size=[]),\n",
        "            frames_per_batch=episodes,\n",
        "            total_frames=episodes\n",
        "        ) \n",
        "       \n",
        "        actor = Actor(\n",
        "            module=model.actor,\n",
        "            in_keys=[\"_features\"],\n",
        "            out_keys=[\"action\"],\n",
        "            distribution_class=Categorical,    # <-- Important!\n",
        "            distribution_kwargs={\"logits\": True},\n",
        "            return_log_prob=True,\n",
        "        )\n",
        "\n",
        "        critic = TensorDictModule(\n",
        "            module=model.critic,\n",
        "            in_keys=[\"_features\"],\n",
        "            out_keys=[\"state_value\"]\n",
        "        )\n",
        "\n",
        "        loss_module = A2CLoss(actor_network=model.actor, critic_network=model.critic)\n",
        "        loss_module.make_value_estimator(ValueEstimators.TD0, gamma=gamma)\n",
        "        buffer = ReplayBuffer(storage=LazyTensorStorage(max_size=episodes))\n",
        "\n",
        "        for i, tensordict_data in enumerate(collector):\n",
        "            buffer.extend(tensordict_data)\n",
        "\n",
        "            sampled_data = buffer.sample(batch_size=episodes)\n",
        "\n",
        "            loss_td = loss_module(sampled_data)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss_td[\"loss\"].backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            print(f\"[{ticker}] Episode {i+1}/{episodes} | Loss: {loss_td['loss'].item():.4f}\")\n",
        "\n",
        "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "        print(f\"[{ticker}] Training complete and model saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VPPJh-7am_Bq",
        "outputId": "df191946-a1db-4c90-d1c9-5fa4f799087c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "  No existing model found — initialized new network.\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "SafeModule.__init__() got an unexpected keyword argument 'distribution_class'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[265], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run training\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[264], line 34\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(dataset, episodes, gamma, lr)\u001b[0m\n\u001b[0;32m     25\u001b[0m env \u001b[38;5;241m=\u001b[39m TradingEnv(stock_data, window_size\u001b[38;5;241m=\u001b[39mwindow_size)\n\u001b[0;32m     27\u001b[0m collector \u001b[38;5;241m=\u001b[39m SyncDataCollector(\n\u001b[0;32m     28\u001b[0m     create_env_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m: env,\n\u001b[0;32m     29\u001b[0m     policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m td: TensorDict({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction\u001b[39m\u001b[38;5;124m\"\u001b[39m: Categorical(logits\u001b[38;5;241m=\u001b[39mmodel(td))\u001b[38;5;241m.\u001b[39msample()}, batch_size\u001b[38;5;241m=\u001b[39m[]),\n\u001b[0;32m     30\u001b[0m     frames_per_batch\u001b[38;5;241m=\u001b[39mepisodes,\n\u001b[0;32m     31\u001b[0m     total_frames\u001b[38;5;241m=\u001b[39mepisodes\n\u001b[0;32m     32\u001b[0m ) \n\u001b[1;32m---> 34\u001b[0m actor \u001b[38;5;241m=\u001b[39m \u001b[43mActor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_features\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCategorical\u001b[49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# <-- Important!\u001b[39;49;00m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogits\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_log_prob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m critic \u001b[38;5;241m=\u001b[39m TensorDictModule(\n\u001b[0;32m     44\u001b[0m     module\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mcritic,\n\u001b[0;32m     45\u001b[0m     in_keys\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_features\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     46\u001b[0m     out_keys\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_value\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     47\u001b[0m )\n\u001b[0;32m     49\u001b[0m loss_module \u001b[38;5;241m=\u001b[39m A2CLoss(actor_network\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mactor, critic_network\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mcritic)\n",
            "File \u001b[1;32mc:\\Users\\shmue\\projects\\python\\open_pojects\\probability_of_market_movment\\.venv\\lib\\site-packages\\torchrl\\modules\\tensordict_module\\actors.py:118\u001b[0m, in \u001b[0;36mActor.__init__\u001b[1;34m(self, module, in_keys, out_keys, spec, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m out_keys\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(spec, Composite)\n\u001b[0;32m    115\u001b[0m ):\n\u001b[0;32m    116\u001b[0m     spec \u001b[38;5;241m=\u001b[39m Composite(action\u001b[38;5;241m=\u001b[39mspec)\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    119\u001b[0m     module,\n\u001b[0;32m    120\u001b[0m     in_keys\u001b[38;5;241m=\u001b[39min_keys,\n\u001b[0;32m    121\u001b[0m     out_keys\u001b[38;5;241m=\u001b[39mout_keys,\n\u001b[0;32m    122\u001b[0m     spec\u001b[38;5;241m=\u001b[39mspec,\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    124\u001b[0m )\n",
            "\u001b[1;31mTypeError\u001b[0m: SafeModule.__init__() got an unexpected keyword argument 'distribution_class'"
          ]
        }
      ],
      "source": [
        "\n",
        "# Run training\n",
        "train(dataset, episodes=10)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
