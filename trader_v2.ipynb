{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sh20022002/probability_of_change/blob/main/trader_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXajTKy6m_Bl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pickle\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas_ta as ta\n",
        "\n",
        "from torchrl.envs import EnvBase\n",
        "from tensordict import TensorDict\n",
        "from torchrl.envs.utils import step_mdp\n",
        "from torch.distributions import Categorical\n",
        "from tensordict import TensorDict\n",
        "from torchrl.collectors import SyncDataCollector\n",
        "from torchrl.data import ReplayBuffer, LazyTensorStorage\n",
        "from torchrl.objectives import A2CLoss\n",
        "from tensordict import TensorDictBase\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from torchrl.data import UnboundedContinuousTensorSpec, DiscreteTensorSpec\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import  Dataset\n",
        "import torch.optim as optim\n",
        "\n",
        "import collections\n",
        "import warnings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "MODEL_SAVE_PATH = \"trading_model.pth\"\n",
        "SP500_TICKERS = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
        "COLUMNS = ['Open', 'Close', 'Volume', 'MACD', 'ATR'] #change to open close volume macd rsi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class StockDataset(Dataset):\n",
        "    def __init__(self, tickers, num_segments=10):\n",
        "        self.tickers = tickers\n",
        "        self.num_segments = num_segments\n",
        "        self.segmented_data = []\n",
        "        self.current_ticker_idx = 0\n",
        "\n",
        "        self._load_and_split_data()\n",
        "\n",
        "    def _load_and_split_data(self):\n",
        "        saved = False\n",
        "        for ticker in self.tickers:\n",
        "            print(f\"Processing ticker: {ticker}\")\n",
        "\n",
        "            try:\n",
        "                stock_data = yf.download(ticker, period='max', progress=False)\n",
        "                if stock_data.empty:\n",
        "                    print(f\"Warning: Empty data for ticker: {ticker}\")\n",
        "                    return None\n",
        "                \n",
        "                df = stock_data['Open', 'High', 'Low', 'Close', 'Volume'].dropna()\n",
        "\n",
        "                df['MACD'] = ta.macd(df['Close'], fast=12, slow=26, signal=9)['MACD_12_26_9']\n",
        "                df['ATR'] = ta.atr(df['High'], df['Low'], df['Close'], length=14)\n",
        "                \n",
        "                features = df[COLUMNS].dropna()\n",
        "                if features.empty:\n",
        "                    return None\n",
        "\n",
        "                    \n",
        "                # Select features to scale\n",
        "                scaler = StandardScaler()\n",
        "                scaled_data = scaler.fit_transform(features)\n",
        "\n",
        "                # Save the fitted scaler\n",
        "                if not saved:\n",
        "                    os.makedirs(\"data\", exist_ok=True)\n",
        "                    with open(\"data/scaler.pkl\", \"wb\") as f:\n",
        "                        pickle.dump(scaler, f)\n",
        "\n",
        "            except Exception as e:\n",
        "                        print(f\"Error downloading data for {ticker}: {e}\")\n",
        "                        return None\n",
        "\n",
        "            scaled_values = scaled_data.astype(np.float32)\n",
        "            segment_size = len(scaled_values) // self.num_segments\n",
        "            for i in range(self.num_segments):\n",
        "                start = i * segment_size\n",
        "                end = (i + 1) * segment_size if i < self.num_segments - 1 else len(scaled_values)\n",
        "                segment = scaled_values[start:end]\n",
        "                if len(segment) > 0:\n",
        "                    self.segmented_data.append((segment, ticker))\n",
        "                    self.current_ticker_idx += 1\n",
        "\n",
        "            \n",
        "    def __len__(self):\n",
        "        return len(self.segmented_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.segmented_data[idx]\n",
        "\n",
        "\n",
        "    def fetch_next_stock(self):\n",
        "        \"\"\"Returns a dataset segment in order, keeping track of stock index.\"\"\"\n",
        "        if not self.segmented_data:\n",
        "            return None, None  # No more stocks\n",
        "\n",
        "        if self.current_ticker_idx >= len(self.segmented_data):\n",
        "            self.current_ticker_idx = 0  # Loop back to start\n",
        "\n",
        "        segment, ticker = self.segmented_data[self.current_ticker_idx]\n",
        "        self.current_ticker_idx += 1\n",
        "        return segment, ticker\n",
        "\n",
        "    def save(self, path):\n",
        "        \"\"\"\n",
        "        Saves the StockDataset to a pickle file.\n",
        "\n",
        "        Args:\n",
        "            filepath (str): The path to the pickle file.\n",
        "        \"\"\"\n",
        "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "        with open(path, 'wb') as f:\n",
        "            pickle.dump(self, f)\n",
        "        print('Saved Dataset.')\n",
        "\n",
        "    @staticmethod\n",
        "    def load(path):\n",
        "        \"\"\"\n",
        "        Loads the StockDataset from a pickle file.\n",
        "\n",
        "        Args:\n",
        "            filepath (str): The path to the pickle file.\n",
        "\n",
        "        Returns:\n",
        "            StockDataset: The loaded StockDataset object.\n",
        "        \"\"\"\n",
        "        with open(path, 'rb') as f:\n",
        "            return pickle.load(f)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TradingEnv(EnvBase):\n",
        "    def __init__(self, df: pd.DataFrame, window_size=30):\n",
        "        super().__init__()\n",
        "\n",
        "        if isinstance(df, np.ndarray):\n",
        "            df = pd.DataFrame(df)\n",
        "\n",
        "        if len(df) < window_size:\n",
        "            raise ValueError(f\"Insufficient data: need at least {window_size} rows, got {len(df)}.\")\n",
        "\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.initial_balance = 1000.0\n",
        "        self.balance = 1000.0\n",
        "        self.net_worth = 1000.0\n",
        "        self.window_size = window_size\n",
        "        self.current_step = 0\n",
        "\n",
        "        obs_dim = window_size * self.df.shape[1]\n",
        "        self.observation_spec = UnboundedContinuousTensorSpec(shape=(obs_dim,))\n",
        "        self.action_spec = DiscreteTensorSpec(n=4)\n",
        "\n",
        "        self._set_seed(0)\n",
        "\n",
        "    def _reset(self, tensordict=None):\n",
        "        self.current_step = self.window_size\n",
        "        self.balance = self.initial_balance\n",
        "        self.net_worth = self.initial_balance\n",
        "        self.positions = []\n",
        "        self.position_type = None\n",
        "        self.trades = []\n",
        "\n",
        "        obs = self._get_observation()\n",
        "        return TensorDict({\"observation\": obs.unsqueeze(0)}, batch_size=[])\n",
        "\n",
        "    def _get_observation(self):\n",
        "        frame = self.df.iloc[self.current_step - self.window_size:self.current_step].copy()\n",
        "        frame[\"Balance\"] = self.balance\n",
        "        frame[\"NetWorth\"] = self.net_worth\n",
        "\n",
        "        obs = torch.tensor(frame.astype(np.float32).values, dtype=torch.float32)\n",
        "        return obs\n",
        "\n",
        "    def _set_seed(self, seed: int):\n",
        "        torch.manual_seed(seed)\n",
        "        np.random.seed(seed)\n",
        "        random.seed(seed)\n",
        "        return seed\n",
        "\n",
        "    def _step(self, tensordict):\n",
        "        action = tensordict[\"action\"].item()\n",
        "        reward = 0.0\n",
        "        done = False\n",
        "\n",
        "        current_price = self.df.loc[self.current_step, 'Close']\n",
        "\n",
        "        if action == 0:  # Buy\n",
        "            if self.position_type is None:\n",
        "                self.positions.append(current_price)\n",
        "                self.position_type = 'long'\n",
        "            elif self.position_type == 'short':\n",
        "                entry = self.positions.pop(0)\n",
        "                profit = entry - current_price\n",
        "                reward += profit\n",
        "                self.balance += profit\n",
        "                if not self.positions:\n",
        "                    self.position_type = None\n",
        "\n",
        "        elif action == 1:  # Sell\n",
        "            if self.position_type == 'long':\n",
        "                entry = self.positions.pop(0)\n",
        "                profit = current_price - entry\n",
        "                reward += profit\n",
        "                self.balance += profit\n",
        "                if not self.positions:\n",
        "                    self.position_type = None\n",
        "\n",
        "        elif action == 2:  # Short\n",
        "            if self.position_type is None:\n",
        "                self.positions.append(current_price)\n",
        "                self.position_type = 'short'\n",
        "            elif self.position_type == 'long':\n",
        "                entry = self.positions.pop(0)\n",
        "                profit = current_price - entry\n",
        "                reward += profit\n",
        "                self.balance += profit\n",
        "                if not self.positions:\n",
        "                    self.position_type = None\n",
        "\n",
        "        elif action == 3:  # Cover\n",
        "            if self.position_type == 'short':\n",
        "                entry = self.positions.pop(0)\n",
        "                profit = entry - current_price\n",
        "                reward += profit\n",
        "                self.balance += profit\n",
        "                if not self.positions:\n",
        "                    self.position_type = None\n",
        "\n",
        "        self.net_worth = self.balance\n",
        "        self.trades.append((self.current_step, action, current_price, reward))\n",
        "\n",
        "        self.current_step += 1\n",
        "        if self.current_step >= len(self.df):\n",
        "            done = True\n",
        "\n",
        "        next_obs = self._get_observation()\n",
        "\n",
        "        return TensorDict({\n",
        "            \"next\": TensorDict({\"observation\": next_obs.unsqueeze(0)}, batch_size=[]),\n",
        "            \"reward\": torch.tensor([reward], dtype=torch.float32),\n",
        "            \"done\": torch.tensor([done], dtype=torch.bool),\n",
        "            \"terminated\": torch.tensor([done], dtype=torch.bool),\n",
        "        }, batch_size=[])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model(stock_data, model):\n",
        "    \"\"\"Evaluates the model on stock data and returns total reward.\"\"\"\n",
        "    env = TradingEnv(stock_data)\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "    actions = []\n",
        "\n",
        "    while not done:\n",
        "        with torch.inference_mode:\n",
        "            state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0)\n",
        "            logits, value, _ = model(state_tensor)\n",
        "            action = torch.argmax(logits).item()\n",
        "\n",
        "\n",
        "        actions.append(action)\n",
        "        state, reward, done, _ = env.step(action)\n",
        "        total_reward += reward\n",
        "\n",
        "    return total_reward, actions\n",
        "\n",
        "# Function to plot evaluation results\n",
        "def plot_evaluation_results(stock_data, actions):\n",
        "    \"\"\"Plots stock data and overlays model evaluation results.\"\"\"\n",
        "    close_prices = stock_data[:, 3]  # Close prices\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(close_prices, label=\"Close Price\", color='black')\n",
        "\n",
        "    buy_signals = [i for i in range(len(actions)) if actions[i] == 1]\n",
        "    sell_signals = [i for i in range(len(actions)) if actions[i] == 2]\n",
        "\n",
        "    plt.scatter(buy_signals, close_prices[buy_signals], color='green', marker='^', label='Buy')\n",
        "    plt.scatter(sell_signals, close_prices[sell_signals], color='red', marker='v', label='Sell')\n",
        "\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel(\"Stock Price\")\n",
        "    plt.legend()\n",
        "    plt.title(f\"Model Evaluation Results\")\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "UsVD4Tjim_Bp"
      },
      "outputs": [],
      "source": [
        "\n",
        "if os.path.exists(\"data/stock_dataset.pkl\"):\n",
        "    dataset = StockDataset.load(\"data/stock_dataset.pkl\")\n",
        "else:\n",
        "    tickers = pd.read_html(SP500_TICKERS)[0]['Symbol'].tolist()\n",
        "    dataset = StockDataset(tickers, num_segments=10)\n",
        "    dataset.save(\"data/stock_dataset.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class StockLSTM(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=128, lstm_layers=2, fc_dim=64, output_dim=4):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.lstm_layers = lstm_layers\n",
        "\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, lstm_layers, batch_first=True, dropout=0.2 if lstm_layers > 1 else 0.0)\n",
        "        self.norm = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "        self.actor = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, fc_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(fc_dim, output_dim)\n",
        "        )\n",
        "\n",
        "        self.critic = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, fc_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(fc_dim, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, tensordict: TensorDictBase):\n",
        "        obs = tensordict[\"observation\"]  # Shape: (B, T, input_dim)\n",
        "\n",
        "        if obs.ndim == 2:\n",
        "            obs = obs.unsqueeze(0)\n",
        "\n",
        "        # Get sequence lengths or default to full length\n",
        "        lengths = tensordict.get(\"lengths\", torch.full((obs.size(0),), obs.size(1), dtype=torch.long, device=obs.device))\n",
        "\n",
        "        # Pack padded sequences for LSTM\n",
        "        packed = pack_padded_sequence(obs, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "        packed_out, _ = self.lstm(packed)\n",
        "        lstm_out, _ = pad_packed_sequence(packed_out, batch_first=True)\n",
        "\n",
        "        # Gather last output per sequence (according to actual length)\n",
        "        idx = (lengths - 1).view(-1, 1, 1).expand(-1, 1, self.hidden_dim)\n",
        "        last_out = lstm_out.gather(1, idx).squeeze(1)  # Shape: (B, hidden_dim)\n",
        "\n",
        "        last_out = self.norm(last_out)\n",
        "\n",
        "        logits = self.actor(last_out)\n",
        "        value = self.critic(last_out)\n",
        "\n",
        "        tensordict.set(\"logits\", logits)\n",
        "        tensordict.set(\"value\", value)\n",
        "        return tensordict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {},
      "outputs": [],
      "source": [
        "def init_or_load(input_dim: int = 7,\n",
        "                     output_dim: int = 3,\n",
        "                     lr: float = 1e-3,\n",
        "                     memory_size: int = 10_000):\n",
        "    \"\"\"\n",
        "    Returns (model, optimizer, memory), loading pretrained weights if available.\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Using device:\", device)\n",
        "\n",
        "    model = StockLSTM(input_dim=input_dim, output_dim=output_dim).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    memory = collections.deque(maxlen=memory_size)\n",
        "\n",
        "    if os.path.exists(MODEL_SAVE_PATH):\n",
        "        model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
        "        print(f\" Loaded existing model from {MODEL_SAVE_PATH}\")\n",
        "    else:\n",
        "        print(\"  No existing model found — initialized new network.\")\n",
        "\n",
        "    return model, optimizer, memory, device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def convert_state(state):\n",
        "    if isinstance(state, np.ndarray):\n",
        "        state = torch.tensor(state, dtype=torch.float32)\n",
        "    if isinstance(state, list):\n",
        "        state = torch.tensor(state, dtype=torch.float32)\n",
        "    if state.ndim == 2:\n",
        "        state = state.unsqueeze(0)\n",
        "    return state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def train(dataset, episodes=10, gamma=0.95, lr=1e-3):\n",
        "    model, optimizer, _, device = init_or_load(input_dim=7, output_dim=4, lr=lr)\n",
        "    model = model.to(device)\n",
        "    optimizer = optimizer.to(device)\n",
        "\n",
        "    if os.path.exists(MODEL_SAVE_PATH):\n",
        "        model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
        "        print(\"Loaded existing model.\")\n",
        "\n",
        "    window_size = 7\n",
        "\n",
        "    while True:\n",
        "        stock_data, ticker = dataset.fetch_next_stock()\n",
        "        if stock_data is None:\n",
        "            print(\"All data segments processed, restarting training loop...\")\n",
        "            break\n",
        "\n",
        "        if isinstance(stock_data, np.ndarray):\n",
        "            stock_data = pd.DataFrame(stock_data)\n",
        "\n",
        "        if len(stock_data) < window_size:\n",
        "            print(f\"Skipping stock {ticker}: only {len(stock_data)} rows (<{window_size}).\")\n",
        "            continue\n",
        "\n",
        "        env = TradingEnv(stock_data, window_size=window_size)\n",
        "\n",
        "        collector = SyncDataCollector(\n",
        "            create_env_fn=lambda: env,\n",
        "            policy=lambda td: TensorDict({\"action\": Categorical(logits=model(td[\"observation\"]))}, batch_size=[]),\n",
        "            frames_per_batch=episodes,\n",
        "            total_frames=episodes\n",
        "        )\n",
        "\n",
        "        loss_module = A2CLoss(model, gamma=gamma)\n",
        "\n",
        "        buffer = ReplayBuffer(storage=LazyTensorStorage(max_size=episodes))\n",
        "\n",
        "        for i, tensordict_data in enumerate(collector):\n",
        "            buffer.extend(tensordict_data)\n",
        "\n",
        "            sampled_data = buffer.sample(batch_size=episodes)\n",
        "\n",
        "            loss_td = loss_module(sampled_data)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss_td[\"loss\"].backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            print(f\"[{ticker}] Episode {i+1}/{episodes} | Loss: {loss_td['loss'].item():.4f}\")\n",
        "\n",
        "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "        print(f\"[{ticker}] Training complete and model saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VPPJh-7am_Bq",
        "outputId": "df191946-a1db-4c90-d1c9-5fa4f799087c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "  No existing model found — initialized new network.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\shmue\\projects\\python\\open_pojects\\probability_of_market_movment\\.venv\\lib\\site-packages\\torchrl\\data\\tensor_specs.py:6294: DeprecationWarning: The UnboundedContinuousTensorSpec has been deprecated and will be removed in v0.8. Please use Unbounded instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\shmue\\projects\\python\\open_pojects\\probability_of_market_movment\\.venv\\lib\\site-packages\\torchrl\\data\\tensor_specs.py:6294: DeprecationWarning: The DiscreteTensorSpec has been deprecated and will be removed in v0.8. Please use Categorical instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "too many indices for tensor of dimension 3",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[182], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run training\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[181], line 26\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(dataset, episodes, gamma, lr)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     24\u001b[0m env \u001b[38;5;241m=\u001b[39m TradingEnv(stock_data, window_size\u001b[38;5;241m=\u001b[39mwindow_size)\n\u001b[1;32m---> 26\u001b[0m collector \u001b[38;5;241m=\u001b[39m \u001b[43mSyncDataCollector\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_env_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtd\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mTensorDict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mCategorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtd\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mobservation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframes_per_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepisodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_frames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepisodes\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m loss_module \u001b[38;5;241m=\u001b[39m A2CLoss(model, gamma\u001b[38;5;241m=\u001b[39mgamma)\n\u001b[0;32m     35\u001b[0m buffer \u001b[38;5;241m=\u001b[39m ReplayBuffer(storage\u001b[38;5;241m=\u001b[39mLazyTensorStorage(max_size\u001b[38;5;241m=\u001b[39mepisodes))\n",
            "File \u001b[1;32mc:\\Users\\shmue\\projects\\python\\open_pojects\\probability_of_market_movment\\.venv\\lib\\site-packages\\torchrl\\collectors\\collectors.py:771\u001b[0m, in \u001b[0;36mSyncDataCollector.__init__\u001b[1;34m(self, create_env_fn, policy, frames_per_batch, total_frames, device, storing_device, policy_device, env_device, create_env_kwargs, max_frames_per_traj, init_random_frames, reset_at_each_iter, postproc, split_trajs, exploration_type, return_same_td, reset_when_done, interruptor, set_truncated, use_buffers, replay_buffer, trust_policy, compile_policy, cudagraph_policy, no_cuda_sync, **kwargs)\u001b[0m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_truncated \u001b[38;5;241m=\u001b[39m set_truncated\n\u001b[0;32m    770\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_shuttle()\n\u001b[1;32m--> 771\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_make_final_rollout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmake_rollout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_use_buffers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_truncated_keys()\n\u001b[0;32m    774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m split_trajs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\shmue\\projects\\python\\open_pojects\\probability_of_market_movment\\.venv\\lib\\site-packages\\torchrl\\collectors\\collectors.py:875\u001b[0m, in \u001b[0;36mSyncDataCollector._maybe_make_final_rollout\u001b[1;34m(self, make_rollout)\u001b[0m\n\u001b[0;32m    873\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompiled_policy:\n\u001b[0;32m    874\u001b[0m     cudagraph_mark_step_begin()\n\u001b[1;32m--> 875\u001b[0m policy_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolicy_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# check that we don't have exclusive keys, because they don't appear in keys\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcheck_exclusive\u001b[39m(val):\n",
            "Cell \u001b[1;32mIn[181], line 28\u001b[0m, in \u001b[0;36mtrain.<locals>.<lambda>\u001b[1;34m(td)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     24\u001b[0m env \u001b[38;5;241m=\u001b[39m TradingEnv(stock_data, window_size\u001b[38;5;241m=\u001b[39mwindow_size)\n\u001b[0;32m     26\u001b[0m collector \u001b[38;5;241m=\u001b[39m SyncDataCollector(\n\u001b[0;32m     27\u001b[0m     create_env_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m: env,\n\u001b[1;32m---> 28\u001b[0m     policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m td: TensorDict({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction\u001b[39m\u001b[38;5;124m\"\u001b[39m: Categorical(logits\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtd\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mobservation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)}, batch_size\u001b[38;5;241m=\u001b[39m[]),\n\u001b[0;32m     29\u001b[0m     frames_per_batch\u001b[38;5;241m=\u001b[39mepisodes,\n\u001b[0;32m     30\u001b[0m     total_frames\u001b[38;5;241m=\u001b[39mepisodes\n\u001b[0;32m     31\u001b[0m )\n\u001b[0;32m     33\u001b[0m loss_module \u001b[38;5;241m=\u001b[39m A2CLoss(model, gamma\u001b[38;5;241m=\u001b[39mgamma)\n\u001b[0;32m     35\u001b[0m buffer \u001b[38;5;241m=\u001b[39m ReplayBuffer(storage\u001b[38;5;241m=\u001b[39mLazyTensorStorage(max_size\u001b[38;5;241m=\u001b[39mepisodes))\n",
            "File \u001b[1;32mc:\\Users\\shmue\\projects\\python\\open_pojects\\probability_of_market_movment\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\shmue\\projects\\python\\open_pojects\\probability_of_market_movment\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[1;32mIn[178], line 23\u001b[0m, in \u001b[0;36mStockLSTM.forward\u001b[1;34m(self, tensordict)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensordict: TensorDictBase):\n\u001b[1;32m---> 23\u001b[0m     obs \u001b[38;5;241m=\u001b[39m \u001b[43mtensordict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mobservation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Shape: (B, T, input_dim)\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obs\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m     26\u001b[0m         obs \u001b[38;5;241m=\u001b[39m obs\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n",
            "\u001b[1;31mIndexError\u001b[0m: too many indices for tensor of dimension 3"
          ]
        }
      ],
      "source": [
        "\n",
        "# Run training\n",
        "train(dataset, episodes=10)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
